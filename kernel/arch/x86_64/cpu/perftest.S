.code64
.section .text, "ax", @progbits

// Load segments 256,000,000 times from top of stack
// old way 136 cycles
.global mov_seg_perf
mov_seg_perf:
	push $ 0
	mov $ 1000000,%ecx

	xor %eax,%eax
.balign 16
0:	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	mov (%rsp),%rax
	mov %ax,%ds
	shr $ 16,%rax
	mov %ax,%es
	shr $ 16,%rax
	mov %ax,%fs
	shr $ 16,%rax
	mov %ax,%gs
	dec %ecx
	jnz 0b
	pop %rax
	ret

// Load segments 256,000,000 times from top of stack
.global str_seg_perf
str_seg_perf:
	push $ 0
	mov $ 1000000,%ecx

.balign 16
0:	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	mov %ds,(%rsp)
	mov %es,2(%rsp)
	mov %fs,4(%rsp)
	mov %gs,6(%rsp)
	dec %ecx
	jnz 0b
	pop %rax
	ret

.macro between
	xor %rdi,%rbx
	xor %rdi,%rbx
	xor %rdi,%rbx
	xor %rdi,%rbx
	xor %rdi,%rbx
	xor %rdi,%rbx
	xor %rdi,%rbx
	xor %rdi,%rbx
	xor %rdi,%rbx
	xor %rdi,%rbx
	xor %rdi,%rbx
	xor %rdi,%rbx
	xor %rdi,%rbx
	xor %rdi,%rbx
	xor %rdi,%rbx
	xor %rdi,%rbx
.endm

.macro iter
	mov (%rsp),%rax
	mov $ CPU_MSR_FSBASE,%ecx
	mov %rax,%rdx
	shr $ 32,%rdx
	wrmsr

	between
	between
	between
	between
.endm

.macro iter_block
	iter
	iter
	iter
	iter
	iter
	iter
	iter
	iter
.endm

.global rdfsbase_perf
rdfsbase_perf:
	movabs $ 0xFFFF800042424242,%rax
	mov %rax,%rdi
	xor %ebx,%ebx
	push %rax
	mov $ 60000000,%esi

.balign 16
0:	iter_block
	iter_block
	iter_block
	iter_block
	iter_block
	iter_block
	iter_block
	iter_block

	dec %esi
	jnz 0b
	pop %rax
	ret
