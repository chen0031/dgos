// THIS FILE IS AUTOMATICALLY GENERATED
// from kernel/device/nvme/nvme.bits

//
// NVME_CAP: Capabilities


// Memory page size maximum (2 ^ (12 + MPSMAX))
#define NVME_CAP_MPSMAX_BIT       52

// Memory page size minimum (2 ^ (12 + MPSMIN))
#define NVME_CAP_MPSMIN_BIT       48

// Command sets supported
#define NVME_CAP_CSS_BIT          37

// NVM subsystem reset supported
#define NVME_CAP_NSSRS_BIT        36

// Doorbell stride (2 ^ (2 + DSTRD))
#define NVME_CAP_DSTRD_BIT        32

// Timeout (500ms increments)
#define NVME_CAP_TO_BIT           24

// Arbitration mechanism supported
#define NVME_CAP_AMS_BIT          17

// Contiguous queues required
#define NVME_CAP_CQR_BIT          16

// Maximum queue entries supported
#define NVME_CAP_MQES_BIT         0


// Memory page size maximum (2 ^ (12 + MPSMAX))
#define NVME_CAP_MPSMAX_BITS      4

// Memory page size minimum (2 ^ (12 + MPSMIN))
#define NVME_CAP_MPSMIN_BITS      4

// Command sets supported
#define NVME_CAP_CSS_BITS         8

// NVM subsystem reset supported
#define NVME_CAP_NSSRS_BITS       1

// Doorbell stride (2 ^ (2 + DSTRD))
#define NVME_CAP_DSTRD_BITS       4

// Timeout (500ms increments)
#define NVME_CAP_TO_BITS          8

// Arbitration mechanism supported
#define NVME_CAP_AMS_BITS         2

// Contiguous queues required
#define NVME_CAP_CQR_BITS         1

// Maximum queue entries supported
#define NVME_CAP_MQES_BITS        16

// Memory page size maximum (2 ^ (12 + MPSMAX))
#define NVME_CAP_MPSMAX_MASK      ((1UL << NVME_CAP_MPSMAX_BITS)-1)

// Memory page size minimum (2 ^ (12 + MPSMIN))
#define NVME_CAP_MPSMIN_MASK      ((1UL << NVME_CAP_MPSMIN_BITS)-1)

// Command sets supported
#define NVME_CAP_CSS_MASK         ((1UL << NVME_CAP_CSS_BITS)-1)

// NVM subsystem reset supported
#define NVME_CAP_NSSRS_MASK       ((1UL << NVME_CAP_NSSRS_BITS)-1)

// Doorbell stride (2 ^ (2 + DSTRD))
#define NVME_CAP_DSTRD_MASK       ((1UL << NVME_CAP_DSTRD_BITS)-1)

// Timeout (500ms increments)
#define NVME_CAP_TO_MASK          ((1UL << NVME_CAP_TO_BITS)-1)

// Arbitration mechanism supported
#define NVME_CAP_AMS_MASK         ((1UL << NVME_CAP_AMS_BITS)-1)

// Contiguous queues required
#define NVME_CAP_CQR_MASK         ((1UL << NVME_CAP_CQR_BITS)-1)

// Maximum queue entries supported
#define NVME_CAP_MQES_MASK        ((1UL << NVME_CAP_MQES_BITS)-1)

// Memory page size maximum (2 ^ (12 + MPSMAX))
#define NVME_CAP_MPSMAX           (NVME_CAP_MPSMAX_MASK << NVME_CAP_MPSMAX_BIT)

// Memory page size minimum (2 ^ (12 + MPSMIN))
#define NVME_CAP_MPSMIN           (NVME_CAP_MPSMIN_MASK << NVME_CAP_MPSMIN_BIT)

// Command sets supported
#define NVME_CAP_CSS              (NVME_CAP_CSS_MASK << NVME_CAP_CSS_BIT)

// NVM subsystem reset supported
#define NVME_CAP_NSSRS            (NVME_CAP_NSSRS_MASK << NVME_CAP_NSSRS_BIT)

// Doorbell stride (2 ^ (2 + DSTRD))
#define NVME_CAP_DSTRD            (NVME_CAP_DSTRD_MASK << NVME_CAP_DSTRD_BIT)

// Timeout (500ms increments)
#define NVME_CAP_TO               (NVME_CAP_TO_MASK << NVME_CAP_TO_BIT)

// Arbitration mechanism supported
#define NVME_CAP_AMS              (NVME_CAP_AMS_MASK << NVME_CAP_AMS_BIT)

// Contiguous queues required
#define NVME_CAP_CQR              (NVME_CAP_CQR_MASK << NVME_CAP_CQR_BIT)

// Maximum queue entries supported
#define NVME_CAP_MQES             (NVME_CAP_MQES_MASK << NVME_CAP_MQES_BIT)


// Memory page size maximum (2 ^ (12 + MPSMAX))
#define NVME_CAP_MPSMAX_n(n)      (uint64_t(n) << NVME_CAP_MPSMAX_BIT)

// Memory page size minimum (2 ^ (12 + MPSMIN))
#define NVME_CAP_MPSMIN_n(n)      (uint64_t(n) << NVME_CAP_MPSMIN_BIT)

// Command sets supported
#define NVME_CAP_CSS_n(n)         (uint64_t(n) << NVME_CAP_CSS_BIT)

// NVM subsystem reset supported
#define NVME_CAP_NSSRS_n(n)       (uint64_t(n) << NVME_CAP_NSSRS_BIT)

// Doorbell stride (2 ^ (2 + DSTRD))
#define NVME_CAP_DSTRD_n(n)       (uint64_t(n) << NVME_CAP_DSTRD_BIT)

// Timeout (500ms increments)
#define NVME_CAP_TO_n(n)          (uint64_t(n) << NVME_CAP_TO_BIT)

// Arbitration mechanism supported
#define NVME_CAP_AMS_n(n)         (uint64_t(n) << NVME_CAP_AMS_BIT)

// Contiguous queues required
#define NVME_CAP_CQR_n(n)         (uint64_t(n) << NVME_CAP_CQR_BIT)

// Maximum queue entries supported
#define NVME_CAP_MQES_n(n)        (uint64_t(n) << NVME_CAP_MQES_BIT)


// Memory page size maximum (2 ^ (12 + MPSMAX))
#define NVME_CAP_MPSMAX_GET(n) \
    (((n) >> NVME_CAP_MPSMAX_BIT) & NVME_CAP_MPSMAX_MASK)

// Memory page size minimum (2 ^ (12 + MPSMIN))
#define NVME_CAP_MPSMIN_GET(n) \
    (((n) >> NVME_CAP_MPSMIN_BIT) & NVME_CAP_MPSMIN_MASK)

// Command sets supported
#define NVME_CAP_CSS_GET(n) \
    (((n) >> NVME_CAP_CSS_BIT) & NVME_CAP_CSS_MASK)

// NVM subsystem reset supported
#define NVME_CAP_NSSRS_GET(n) \
    (((n) >> NVME_CAP_NSSRS_BIT) & NVME_CAP_NSSRS_MASK)

// Doorbell stride (2 ^ (2 + DSTRD))
#define NVME_CAP_DSTRD_GET(n) \
    (((n) >> NVME_CAP_DSTRD_BIT) & NVME_CAP_DSTRD_MASK)

// Timeout (500ms increments)
#define NVME_CAP_TO_GET(n)        (((n) >> NVME_CAP_TO_BIT) & NVME_CAP_TO_MASK)

// Arbitration mechanism supported
#define NVME_CAP_AMS_GET(n) \
    (((n) >> NVME_CAP_AMS_BIT) & NVME_CAP_AMS_MASK)

// Contiguous queues required
#define NVME_CAP_CQR_GET(n) \
    (((n) >> NVME_CAP_CQR_BIT) & NVME_CAP_CQR_MASK)

// Maximum queue entries supported
#define NVME_CAP_MQES_GET(n) \
    (((n) >> NVME_CAP_MQES_BIT) & NVME_CAP_MQES_MASK)


// Memory page size maximum (2 ^ (12 + MPSMAX))
#define NVME_CAP_MPSMAX_SET(r,n) \
    ((r) = ((r) & ~NVME_CAP_MPSMAX) | NVME_CAP_MPSMAX_n((n)))

// Memory page size minimum (2 ^ (12 + MPSMIN))
#define NVME_CAP_MPSMIN_SET(r,n) \
    ((r) = ((r) & ~NVME_CAP_MPSMIN) | NVME_CAP_MPSMIN_n((n)))

// Command sets supported
#define NVME_CAP_CSS_SET(r,n) \
    ((r) = ((r) & ~NVME_CAP_CSS) | NVME_CAP_CSS_n((n)))

// NVM subsystem reset supported
#define NVME_CAP_NSSRS_SET(r,n) \
    ((r) = ((r) & ~NVME_CAP_NSSRS) | NVME_CAP_NSSRS_n((n)))

// Doorbell stride (2 ^ (2 + DSTRD))
#define NVME_CAP_DSTRD_SET(r,n) \
    ((r) = ((r) & ~NVME_CAP_DSTRD) | NVME_CAP_DSTRD_n((n)))

// Timeout (500ms increments)
#define NVME_CAP_TO_SET(r,n) \
    ((r) = ((r) & ~NVME_CAP_TO) | NVME_CAP_TO_n((n)))

// Arbitration mechanism supported
#define NVME_CAP_AMS_SET(r,n) \
    ((r) = ((r) & ~NVME_CAP_AMS) | NVME_CAP_AMS_n((n)))

// Contiguous queues required
#define NVME_CAP_CQR_SET(r,n) \
    ((r) = ((r) & ~NVME_CAP_CQR) | NVME_CAP_CQR_n((n)))

// Maximum queue entries supported
#define NVME_CAP_MQES_SET(r,n) \
    ((r) = ((r) & ~NVME_CAP_MQES) | NVME_CAP_MQES_n((n)))

// NVME_CAP_AMS_WRRWU
#define NVME_CAP_AMS_WRRWU 1

//
// NVME_VS: Version


// Major version number
#define NVME_VS_MJR_BIT       16

// Minor version number
#define NVME_VS_MNR_BIT       8

// Tertiary version number
#define NVME_VS_TER_BIT       0


// Major version number
#define NVME_VS_MJR_BITS      16

// Minor version number
#define NVME_VS_MNR_BITS      8

// Tertiary version number
#define NVME_VS_TER_BITS      8

// Major version number
#define NVME_VS_MJR_MASK      ((1U << NVME_VS_MJR_BITS)-1)

// Minor version number
#define NVME_VS_MNR_MASK      ((1U << NVME_VS_MNR_BITS)-1)

// Tertiary version number
#define NVME_VS_TER_MASK      ((1U << NVME_VS_TER_BITS)-1)

// Major version number
#define NVME_VS_MJR           (NVME_VS_MJR_MASK << NVME_VS_MJR_BIT)

// Minor version number
#define NVME_VS_MNR           (NVME_VS_MNR_MASK << NVME_VS_MNR_BIT)

// Tertiary version number
#define NVME_VS_TER           (NVME_VS_TER_MASK << NVME_VS_TER_BIT)


// Major version number
#define NVME_VS_MJR_n(n)      ((n) << NVME_VS_MJR_BIT)

// Minor version number
#define NVME_VS_MNR_n(n)      ((n) << NVME_VS_MNR_BIT)

// Tertiary version number
#define NVME_VS_TER_n(n)      ((n) << NVME_VS_TER_BIT)


// Major version number
#define NVME_VS_MJR_GET(n)    (((n) >> NVME_VS_MJR_BIT) & NVME_VS_MJR_MASK)

// Minor version number
#define NVME_VS_MNR_GET(n)    (((n) >> NVME_VS_MNR_BIT) & NVME_VS_MNR_MASK)

// Tertiary version number
#define NVME_VS_TER_GET(n)    (((n) >> NVME_VS_TER_BIT) & NVME_VS_TER_MASK)


// Major version number
#define NVME_VS_MJR_SET(r,n)  ((r) = ((r) & ~NVME_VS_MJR) | NVME_VS_MJR_n((n)))

// Minor version number
#define NVME_VS_MNR_SET(r,n)  ((r) = ((r) & ~NVME_VS_MNR) | NVME_VS_MNR_n((n)))

// Tertiary version number
#define NVME_VS_TER_SET(r,n)  ((r) = ((r) & ~NVME_VS_TER) | NVME_VS_TER_n((n)))

//
// NVME_CC: Configuration


// I/O completion queue entry size
#define NVME_CC_IOCQES_BIT       20

// I/O submission queue entry size
#define NVME_CC_IOSQES_BIT       16

// Shutdown notification
#define NVME_CC_SHN_BIT          14

// Arbitration mechanism selected
#define NVME_CC_AMS_BIT          11

// Memory page size
#define NVME_CC_MPS_BIT          7

// I/O command set selected
#define NVME_CC_CCS_BIT          4

// Enable
#define NVME_CC_EN_BIT           0


// I/O completion queue entry size
#define NVME_CC_IOCQES_BITS      4

// I/O submission queue entry size
#define NVME_CC_IOSQES_BITS      4

// Shutdown notification
#define NVME_CC_SHN_BITS         2

// Arbitration mechanism selected
#define NVME_CC_AMS_BITS         3

// Memory page size
#define NVME_CC_MPS_BITS         4

// I/O command set selected
#define NVME_CC_CCS_BITS         3

// Enable
#define NVME_CC_EN_BITS          1

// I/O completion queue entry size
#define NVME_CC_IOCQES_MASK      ((1U << NVME_CC_IOCQES_BITS)-1)

// I/O submission queue entry size
#define NVME_CC_IOSQES_MASK      ((1U << NVME_CC_IOSQES_BITS)-1)

// Shutdown notification
#define NVME_CC_SHN_MASK         ((1U << NVME_CC_SHN_BITS)-1)

// Arbitration mechanism selected
#define NVME_CC_AMS_MASK         ((1U << NVME_CC_AMS_BITS)-1)

// Memory page size
#define NVME_CC_MPS_MASK         ((1U << NVME_CC_MPS_BITS)-1)

// I/O command set selected
#define NVME_CC_CCS_MASK         ((1U << NVME_CC_CCS_BITS)-1)

// Enable
#define NVME_CC_EN_MASK          ((1U << NVME_CC_EN_BITS)-1)

// I/O completion queue entry size
#define NVME_CC_IOCQES           (NVME_CC_IOCQES_MASK << NVME_CC_IOCQES_BIT)

// I/O submission queue entry size
#define NVME_CC_IOSQES           (NVME_CC_IOSQES_MASK << NVME_CC_IOSQES_BIT)

// Shutdown notification
#define NVME_CC_SHN              (NVME_CC_SHN_MASK << NVME_CC_SHN_BIT)

// Arbitration mechanism selected
#define NVME_CC_AMS              (NVME_CC_AMS_MASK << NVME_CC_AMS_BIT)

// Memory page size
#define NVME_CC_MPS              (NVME_CC_MPS_MASK << NVME_CC_MPS_BIT)

// I/O command set selected
#define NVME_CC_CCS              (NVME_CC_CCS_MASK << NVME_CC_CCS_BIT)

// Enable
#define NVME_CC_EN               (NVME_CC_EN_MASK << NVME_CC_EN_BIT)


// I/O completion queue entry size
#define NVME_CC_IOCQES_n(n)      ((n) << NVME_CC_IOCQES_BIT)

// I/O submission queue entry size
#define NVME_CC_IOSQES_n(n)      ((n) << NVME_CC_IOSQES_BIT)

// Shutdown notification
#define NVME_CC_SHN_n(n)         ((n) << NVME_CC_SHN_BIT)

// Arbitration mechanism selected
#define NVME_CC_AMS_n(n)         ((n) << NVME_CC_AMS_BIT)

// Memory page size
#define NVME_CC_MPS_n(n)         ((n) << NVME_CC_MPS_BIT)

// I/O command set selected
#define NVME_CC_CCS_n(n)         ((n) << NVME_CC_CCS_BIT)

// Enable
#define NVME_CC_EN_n(n)          ((n) << NVME_CC_EN_BIT)


// I/O completion queue entry size
#define NVME_CC_IOCQES_GET(n) \
    (((n) >> NVME_CC_IOCQES_BIT) & NVME_CC_IOCQES_MASK)

// I/O submission queue entry size
#define NVME_CC_IOSQES_GET(n) \
    (((n) >> NVME_CC_IOSQES_BIT) & NVME_CC_IOSQES_MASK)

// Shutdown notification
#define NVME_CC_SHN_GET(n)       (((n) >> NVME_CC_SHN_BIT) & NVME_CC_SHN_MASK)

// Arbitration mechanism selected
#define NVME_CC_AMS_GET(n)       (((n) >> NVME_CC_AMS_BIT) & NVME_CC_AMS_MASK)

// Memory page size
#define NVME_CC_MPS_GET(n)       (((n) >> NVME_CC_MPS_BIT) & NVME_CC_MPS_MASK)

// I/O command set selected
#define NVME_CC_CCS_GET(n)       (((n) >> NVME_CC_CCS_BIT) & NVME_CC_CCS_MASK)

// Enable
#define NVME_CC_EN_GET(n)        (((n) >> NVME_CC_EN_BIT) & NVME_CC_EN_MASK)


// I/O completion queue entry size
#define NVME_CC_IOCQES_SET(r,n) \
    ((r) = ((r) & ~NVME_CC_IOCQES) | NVME_CC_IOCQES_n((n)))

// I/O submission queue entry size
#define NVME_CC_IOSQES_SET(r,n) \
    ((r) = ((r) & ~NVME_CC_IOSQES) | NVME_CC_IOSQES_n((n)))

// Shutdown notification
#define NVME_CC_SHN_SET(r,n) \
    ((r) = ((r) & ~NVME_CC_SHN) | NVME_CC_SHN_n((n)))

// Arbitration mechanism selected
#define NVME_CC_AMS_SET(r,n) \
    ((r) = ((r) & ~NVME_CC_AMS) | NVME_CC_AMS_n((n)))

// Memory page size
#define NVME_CC_MPS_SET(r,n) \
    ((r) = ((r) & ~NVME_CC_MPS) | NVME_CC_MPS_n((n)))

// I/O command set selected
#define NVME_CC_CCS_SET(r,n) \
    ((r) = ((r) & ~NVME_CC_CCS) | NVME_CC_CCS_n((n)))

// Enable
#define NVME_CC_EN_SET(r,n) \
    ((r) = ((r) & ~NVME_CC_EN) | NVME_CC_EN_n((n)))

// NVME_CSTS


// Processing paused
#define NVME_CSTS_PP_BIT          5

// NVM subsystem reset occurred
#define NVME_CSTS_NSSRO_BIT       4

// Shutdown status
#define NVME_CSTS_SHST_BIT        2

// Controller fatal status
#define NVME_CSTS_CFS_BIT         1

// Ready
#define NVME_CSTS_RDY_BIT         0


// Processing paused
#define NVME_CSTS_PP_BITS         1

// NVM subsystem reset occurred
#define NVME_CSTS_NSSRO_BITS      1

// Shutdown status
#define NVME_CSTS_SHST_BITS       2

// Controller fatal status
#define NVME_CSTS_CFS_BITS        1

// Ready
#define NVME_CSTS_RDY_BITS        1

// Processing paused
#define NVME_CSTS_PP_MASK         ((1U << NVME_CSTS_PP_BITS)-1)

// NVM subsystem reset occurred
#define NVME_CSTS_NSSRO_MASK      ((1U << NVME_CSTS_NSSRO_BITS)-1)

// Shutdown status
#define NVME_CSTS_SHST_MASK       ((1U << NVME_CSTS_SHST_BITS)-1)

// Controller fatal status
#define NVME_CSTS_CFS_MASK        ((1U << NVME_CSTS_CFS_BITS)-1)

// Ready
#define NVME_CSTS_RDY_MASK        ((1U << NVME_CSTS_RDY_BITS)-1)

// Processing paused
#define NVME_CSTS_PP              (NVME_CSTS_PP_MASK << NVME_CSTS_PP_BIT)

// NVM subsystem reset occurred
#define NVME_CSTS_NSSRO           (NVME_CSTS_NSSRO_MASK << NVME_CSTS_NSSRO_BIT)

// Shutdown status
#define NVME_CSTS_SHST            (NVME_CSTS_SHST_MASK << NVME_CSTS_SHST_BIT)

// Controller fatal status
#define NVME_CSTS_CFS             (NVME_CSTS_CFS_MASK << NVME_CSTS_CFS_BIT)

// Ready
#define NVME_CSTS_RDY             (NVME_CSTS_RDY_MASK << NVME_CSTS_RDY_BIT)


// Processing paused
#define NVME_CSTS_PP_n(n)         ((n) << NVME_CSTS_PP_BIT)

// NVM subsystem reset occurred
#define NVME_CSTS_NSSRO_n(n)      ((n) << NVME_CSTS_NSSRO_BIT)

// Shutdown status
#define NVME_CSTS_SHST_n(n)       ((n) << NVME_CSTS_SHST_BIT)

// Controller fatal status
#define NVME_CSTS_CFS_n(n)        ((n) << NVME_CSTS_CFS_BIT)

// Ready
#define NVME_CSTS_RDY_n(n)        ((n) << NVME_CSTS_RDY_BIT)


// Processing paused
#define NVME_CSTS_PP_GET(n) \
    (((n) >> NVME_CSTS_PP_BIT) & NVME_CSTS_PP_MASK)

// NVM subsystem reset occurred
#define NVME_CSTS_NSSRO_GET(n) \
    (((n) >> NVME_CSTS_NSSRO_BIT) & NVME_CSTS_NSSRO_MASK)

// Shutdown status
#define NVME_CSTS_SHST_GET(n) \
    (((n) >> NVME_CSTS_SHST_BIT) & NVME_CSTS_SHST_MASK)

// Controller fatal status
#define NVME_CSTS_CFS_GET(n) \
    (((n) >> NVME_CSTS_CFS_BIT) & NVME_CSTS_CFS_MASK)

// Ready
#define NVME_CSTS_RDY_GET(n) \
    (((n) >> NVME_CSTS_RDY_BIT) & NVME_CSTS_RDY_MASK)


// Processing paused
#define NVME_CSTS_PP_SET(r,n) \
    ((r) = ((r) & ~NVME_CSTS_PP) | NVME_CSTS_PP_n((n)))

// NVM subsystem reset occurred
#define NVME_CSTS_NSSRO_SET(r,n) \
    ((r) = ((r) & ~NVME_CSTS_NSSRO) | NVME_CSTS_NSSRO_n((n)))

// Shutdown status
#define NVME_CSTS_SHST_SET(r,n) \
    ((r) = ((r) & ~NVME_CSTS_SHST) | NVME_CSTS_SHST_n((n)))

// Controller fatal status
#define NVME_CSTS_CFS_SET(r,n) \
    ((r) = ((r) & ~NVME_CSTS_CFS) | NVME_CSTS_CFS_n((n)))

// Ready
#define NVME_CSTS_RDY_SET(r,n) \
    ((r) = ((r) & ~NVME_CSTS_RDY) | NVME_CSTS_RDY_n((n)))

// NVME_AQA


// Admin completion queue size
#define NVME_AQA_ACQS_BIT       16

// Admin submission queue size
#define NVME_AQA_ASQS_BIT       0


// Admin completion queue size
#define NVME_AQA_ACQS_BITS      12

// Admin submission queue size
#define NVME_AQA_ASQS_BITS      12

// Admin completion queue size
#define NVME_AQA_ACQS_MASK      ((1U << NVME_AQA_ACQS_BITS)-1)

// Admin submission queue size
#define NVME_AQA_ASQS_MASK      ((1U << NVME_AQA_ASQS_BITS)-1)

// Admin completion queue size
#define NVME_AQA_ACQS           (NVME_AQA_ACQS_MASK << NVME_AQA_ACQS_BIT)

// Admin submission queue size
#define NVME_AQA_ASQS           (NVME_AQA_ASQS_MASK << NVME_AQA_ASQS_BIT)


// Admin completion queue size
#define NVME_AQA_ACQS_n(n)      ((n) << NVME_AQA_ACQS_BIT)

// Admin submission queue size
#define NVME_AQA_ASQS_n(n)      ((n) << NVME_AQA_ASQS_BIT)


// Admin completion queue size
#define NVME_AQA_ACQS_GET(n) \
    (((n) >> NVME_AQA_ACQS_BIT) & NVME_AQA_ACQS_MASK)

// Admin submission queue size
#define NVME_AQA_ASQS_GET(n) \
    (((n) >> NVME_AQA_ASQS_BIT) & NVME_AQA_ASQS_MASK)


// Admin completion queue size
#define NVME_AQA_ACQS_SET(r,n) \
    ((r) = ((r) & ~NVME_AQA_ACQS) | NVME_AQA_ACQS_n((n)))

// Admin submission queue size
#define NVME_AQA_ASQS_SET(r,n) \
    ((r) = ((r) & ~NVME_AQA_ASQS) | NVME_AQA_ASQS_n((n)))

// NVME_ASQ


// Admin submission queue base
#define NVME_ASQ_ASQB_BIT       12


// Admin submission queue base
#define NVME_ASQ_ASQB_BITS      52

// Admin submission queue base
#define NVME_ASQ_ASQB_MASK      ((1UL << NVME_ASQ_ASQB_BITS)-1)

// Admin submission queue base
#define NVME_ASQ_ASQB           (NVME_ASQ_ASQB_MASK << NVME_ASQ_ASQB_BIT)


// Admin submission queue base
#define NVME_ASQ_ASQB_n(n)      (uint64_t(n) << NVME_ASQ_ASQB_BIT)


// Admin submission queue base
#define NVME_ASQ_ASQB_GET(n) \
    (((n) >> NVME_ASQ_ASQB_BIT) & NVME_ASQ_ASQB_MASK)


// Admin submission queue base
#define NVME_ASQ_ASQB_SET(r,n) \
    ((r) = ((r) & ~NVME_ASQ_ASQB) | NVME_ASQ_ASQB_n((n)))

// NVME_ACQ


// Admin completion queue base
#define NVME_ACQ_ACQB_BIT       12


// Admin completion queue base
#define NVME_ACQ_ACQB_BITS      52

// Admin completion queue base
#define NVME_ACQ_ACQB_MASK      ((1UL << NVME_ACQ_ACQB_BITS)-1)

// Admin completion queue base
#define NVME_ACQ_ACQB           (NVME_ACQ_ACQB_MASK << NVME_ACQ_ACQB_BIT)


// Admin completion queue base
#define NVME_ACQ_ACQB_n(n)      (uint64_t(n) << NVME_ACQ_ACQB_BIT)


// Admin completion queue base
#define NVME_ACQ_ACQB_GET(n) \
    (((n) >> NVME_ACQ_ACQB_BIT) & NVME_ACQ_ACQB_MASK)


// Admin completion queue base
#define NVME_ACQ_ACQB_SET(r,n) \
    ((r) = ((r) & ~NVME_ACQ_ACQB) | NVME_ACQ_ACQB_n((n)))

// NVME_CMBLOC


// Offset
#define NVME_CMBLOC_OFST_BIT       12

// Base indicator register
#define NVME_CMBLOC_BIR_BIT        0


// Offset
#define NVME_CMBLOC_OFST_BITS      20

// Base indicator register
#define NVME_CMBLOC_BIR_BITS       3

// Offset
#define NVME_CMBLOC_OFST_MASK      ((1U << NVME_CMBLOC_OFST_BITS)-1)

// Base indicator register
#define NVME_CMBLOC_BIR_MASK       ((1U << NVME_CMBLOC_BIR_BITS)-1)

// Offset
#define NVME_CMBLOC_OFST \
    (NVME_CMBLOC_OFST_MASK << NVME_CMBLOC_OFST_BIT)

// Base indicator register
#define NVME_CMBLOC_BIR \
    (NVME_CMBLOC_BIR_MASK << NVME_CMBLOC_BIR_BIT)


// Offset
#define NVME_CMBLOC_OFST_n(n)      ((n) << NVME_CMBLOC_OFST_BIT)

// Base indicator register
#define NVME_CMBLOC_BIR_n(n)       ((n) << NVME_CMBLOC_BIR_BIT)


// Offset
#define NVME_CMBLOC_OFST_GET(n) \
    (((n) >> NVME_CMBLOC_OFST_BIT) & NVME_CMBLOC_OFST_MASK)

// Base indicator register
#define NVME_CMBLOC_BIR_GET(n) \
    (((n) >> NVME_CMBLOC_BIR_BIT) & NVME_CMBLOC_BIR_MASK)


// Offset
#define NVME_CMBLOC_OFST_SET(r,n) \
    ((r) = ((r) & ~NVME_CMBLOC_OFST) | NVME_CMBLOC_OFST_n((n)))

// Base indicator register
#define NVME_CMBLOC_BIR_SET(r,n) \
    ((r) = ((r) & ~NVME_CMBLOC_BIR) | NVME_CMBLOC_BIR_n((n)))

// NVME_CMBSZ


// Size
#define NVME_CMBSZ_SZ_BIT          12

// Size units
#define NVME_CMBSZ_SZU_BIT         8

// Write data support
#define NVME_CMBSZ_WDS_BIT         4

// Read data support
#define NVME_CMBSZ_RDS_BIT         3

// PRP SGL list support
#define NVME_CMBSZ_LISTS_BIT       2

// Completion queue support
#define NVME_CMBSZ_CQS_BIT         1

// Submission queue support
#define NVME_CMBSZ_SQS_BIT         0


// Size
#define NVME_CMBSZ_SZ_BITS         20

// Size units
#define NVME_CMBSZ_SZU_BITS        4

// Write data support
#define NVME_CMBSZ_WDS_BITS        1

// Read data support
#define NVME_CMBSZ_RDS_BITS        1

// PRP SGL list support
#define NVME_CMBSZ_LISTS_BITS      1

// Completion queue support
#define NVME_CMBSZ_CQS_BITS        1

// Submission queue support
#define NVME_CMBSZ_SQS_BITS        1

// Size
#define NVME_CMBSZ_SZ_MASK         ((1U << NVME_CMBSZ_SZ_BITS)-1)

// Size units
#define NVME_CMBSZ_SZU_MASK        ((1U << NVME_CMBSZ_SZU_BITS)-1)

// Write data support
#define NVME_CMBSZ_WDS_MASK        ((1U << NVME_CMBSZ_WDS_BITS)-1)

// Read data support
#define NVME_CMBSZ_RDS_MASK        ((1U << NVME_CMBSZ_RDS_BITS)-1)

// PRP SGL list support
#define NVME_CMBSZ_LISTS_MASK      ((1U << NVME_CMBSZ_LISTS_BITS)-1)

// Completion queue support
#define NVME_CMBSZ_CQS_MASK        ((1U << NVME_CMBSZ_CQS_BITS)-1)

// Submission queue support
#define NVME_CMBSZ_SQS_MASK        ((1U << NVME_CMBSZ_SQS_BITS)-1)

// Size
#define NVME_CMBSZ_SZ              (NVME_CMBSZ_SZ_MASK << NVME_CMBSZ_SZ_BIT)

// Size units
#define NVME_CMBSZ_SZU             (NVME_CMBSZ_SZU_MASK << NVME_CMBSZ_SZU_BIT)

// Write data support
#define NVME_CMBSZ_WDS             (NVME_CMBSZ_WDS_MASK << NVME_CMBSZ_WDS_BIT)

// Read data support
#define NVME_CMBSZ_RDS             (NVME_CMBSZ_RDS_MASK << NVME_CMBSZ_RDS_BIT)

// PRP SGL list support
#define NVME_CMBSZ_LISTS \
    (NVME_CMBSZ_LISTS_MASK << NVME_CMBSZ_LISTS_BIT)

// Completion queue support
#define NVME_CMBSZ_CQS             (NVME_CMBSZ_CQS_MASK << NVME_CMBSZ_CQS_BIT)

// Submission queue support
#define NVME_CMBSZ_SQS             (NVME_CMBSZ_SQS_MASK << NVME_CMBSZ_SQS_BIT)


// Size
#define NVME_CMBSZ_SZ_n(n)         ((n) << NVME_CMBSZ_SZ_BIT)

// Size units
#define NVME_CMBSZ_SZU_n(n)        ((n) << NVME_CMBSZ_SZU_BIT)

// Write data support
#define NVME_CMBSZ_WDS_n(n)        ((n) << NVME_CMBSZ_WDS_BIT)

// Read data support
#define NVME_CMBSZ_RDS_n(n)        ((n) << NVME_CMBSZ_RDS_BIT)

// PRP SGL list support
#define NVME_CMBSZ_LISTS_n(n)      ((n) << NVME_CMBSZ_LISTS_BIT)

// Completion queue support
#define NVME_CMBSZ_CQS_n(n)        ((n) << NVME_CMBSZ_CQS_BIT)

// Submission queue support
#define NVME_CMBSZ_SQS_n(n)        ((n) << NVME_CMBSZ_SQS_BIT)


// Size
#define NVME_CMBSZ_SZ_GET(n) \
    (((n) >> NVME_CMBSZ_SZ_BIT) & NVME_CMBSZ_SZ_MASK)

// Size units
#define NVME_CMBSZ_SZU_GET(n) \
    (((n) >> NVME_CMBSZ_SZU_BIT) & NVME_CMBSZ_SZU_MASK)

// Write data support
#define NVME_CMBSZ_WDS_GET(n) \
    (((n) >> NVME_CMBSZ_WDS_BIT) & NVME_CMBSZ_WDS_MASK)

// Read data support
#define NVME_CMBSZ_RDS_GET(n) \
    (((n) >> NVME_CMBSZ_RDS_BIT) & NVME_CMBSZ_RDS_MASK)

// PRP SGL list support
#define NVME_CMBSZ_LISTS_GET(n) \
    (((n) >> NVME_CMBSZ_LISTS_BIT) & NVME_CMBSZ_LISTS_MASK)

// Completion queue support
#define NVME_CMBSZ_CQS_GET(n) \
    (((n) >> NVME_CMBSZ_CQS_BIT) & NVME_CMBSZ_CQS_MASK)

// Submission queue support
#define NVME_CMBSZ_SQS_GET(n) \
    (((n) >> NVME_CMBSZ_SQS_BIT) & NVME_CMBSZ_SQS_MASK)


// Size
#define NVME_CMBSZ_SZ_SET(r,n) \
    ((r) = ((r) & ~NVME_CMBSZ_SZ) | NVME_CMBSZ_SZ_n((n)))

// Size units
#define NVME_CMBSZ_SZU_SET(r,n) \
    ((r) = ((r) & ~NVME_CMBSZ_SZU) | NVME_CMBSZ_SZU_n((n)))

// Write data support
#define NVME_CMBSZ_WDS_SET(r,n) \
    ((r) = ((r) & ~NVME_CMBSZ_WDS) | NVME_CMBSZ_WDS_n((n)))

// Read data support
#define NVME_CMBSZ_RDS_SET(r,n) \
    ((r) = ((r) & ~NVME_CMBSZ_RDS) | NVME_CMBSZ_RDS_n((n)))

// PRP SGL list support
#define NVME_CMBSZ_LISTS_SET(r,n) \
    ((r) = ((r) & ~NVME_CMBSZ_LISTS) | NVME_CMBSZ_LISTS_n((n)))

// Completion queue support
#define NVME_CMBSZ_CQS_SET(r,n) \
    ((r) = ((r) & ~NVME_CMBSZ_CQS) | NVME_CMBSZ_CQS_n((n)))

// Submission queue support
#define NVME_CMBSZ_SQS_SET(r,n) \
    ((r) = ((r) & ~NVME_CMBSZ_SQS) | NVME_CMBSZ_SQS_n((n)))

//
// NVME_SQyTDBL: Completion queue doorbell


// Submission queue y tail doorbell
#define NVME_SQyTDBL_SQT_BIT       0


// Submission queue y tail doorbell
#define NVME_SQyTDBL_SQT_BITS      16

// Submission queue y tail doorbell
#define NVME_SQyTDBL_SQT_MASK      ((1U << NVME_SQyTDBL_SQT_BITS)-1)

// Submission queue y tail doorbell
#define NVME_SQyTDBL_SQT \
    (NVME_SQyTDBL_SQT_MASK << NVME_SQyTDBL_SQT_BIT)


// Submission queue y tail doorbell
#define NVME_SQyTDBL_SQT_n(n)      ((n) << NVME_SQyTDBL_SQT_BIT)


// Submission queue y tail doorbell
#define NVME_SQyTDBL_SQT_GET(n) \
    (((n) >> NVME_SQyTDBL_SQT_BIT) & NVME_SQyTDBL_SQT_MASK)


// Submission queue y tail doorbell
#define NVME_SQyTDBL_SQT_SET(r,n) \
    ((r) = ((r) & ~NVME_SQyTDBL_SQT) | NVME_SQyTDBL_SQT_n((n)))

//
// NVME_CQyHDBL: Completion queue doorbell


// Completion queue y tail doorbell
#define NVME_CQyHDBL_SQT_BIT       0


// Completion queue y tail doorbell
#define NVME_CQyHDBL_SQT_BITS      16

// Completion queue y tail doorbell
#define NVME_CQyHDBL_SQT_MASK      ((1U << NVME_CQyHDBL_SQT_BITS)-1)

// Completion queue y tail doorbell
#define NVME_CQyHDBL_SQT \
    (NVME_CQyHDBL_SQT_MASK << NVME_CQyHDBL_SQT_BIT)


// Completion queue y tail doorbell
#define NVME_CQyHDBL_SQT_n(n)      ((n) << NVME_CQyHDBL_SQT_BIT)


// Completion queue y tail doorbell
#define NVME_CQyHDBL_SQT_GET(n) \
    (((n) >> NVME_CQyHDBL_SQT_BIT) & NVME_CQyHDBL_SQT_MASK)


// Completion queue y tail doorbell
#define NVME_CQyHDBL_SQT_SET(r,n) \
    ((r) = ((r) & ~NVME_CQyHDBL_SQT) | NVME_CQyHDBL_SQT_n((n)))

//
// NVME_CMD_SDW0: Submission queue entry command dword 0


// Command identifier
#define NVME_CMD_SDW0_CID_BIT        16

// PRP or SGL data transfer
#define NVME_CMD_SDW0_PSDT_BIT       14

// Fused operation
#define NVME_CMD_SDW0_FUSE_BIT       8

// Opcode
#define NVME_CMD_SDW0_OPC_BIT        0


// Command identifier
#define NVME_CMD_SDW0_CID_BITS       16

// PRP or SGL data transfer
#define NVME_CMD_SDW0_PSDT_BITS      2

// Fused operation
#define NVME_CMD_SDW0_FUSE_BITS      2

// Opcode
#define NVME_CMD_SDW0_OPC_BITS       8

// Command identifier
#define NVME_CMD_SDW0_CID_MASK       ((1U << NVME_CMD_SDW0_CID_BITS)-1)

// PRP or SGL data transfer
#define NVME_CMD_SDW0_PSDT_MASK      ((1U << NVME_CMD_SDW0_PSDT_BITS)-1)

// Fused operation
#define NVME_CMD_SDW0_FUSE_MASK      ((1U << NVME_CMD_SDW0_FUSE_BITS)-1)

// Opcode
#define NVME_CMD_SDW0_OPC_MASK       ((1U << NVME_CMD_SDW0_OPC_BITS)-1)

// Command identifier
#define NVME_CMD_SDW0_CID \
    (NVME_CMD_SDW0_CID_MASK << NVME_CMD_SDW0_CID_BIT)

// PRP or SGL data transfer
#define NVME_CMD_SDW0_PSDT \
    (NVME_CMD_SDW0_PSDT_MASK << NVME_CMD_SDW0_PSDT_BIT)

// Fused operation
#define NVME_CMD_SDW0_FUSE \
    (NVME_CMD_SDW0_FUSE_MASK << NVME_CMD_SDW0_FUSE_BIT)

// Opcode
#define NVME_CMD_SDW0_OPC \
    (NVME_CMD_SDW0_OPC_MASK << NVME_CMD_SDW0_OPC_BIT)


// Command identifier
#define NVME_CMD_SDW0_CID_n(n)       ((n) << NVME_CMD_SDW0_CID_BIT)

// PRP or SGL data transfer
#define NVME_CMD_SDW0_PSDT_n(n)      ((n) << NVME_CMD_SDW0_PSDT_BIT)

// Fused operation
#define NVME_CMD_SDW0_FUSE_n(n)      ((n) << NVME_CMD_SDW0_FUSE_BIT)

// Opcode
#define NVME_CMD_SDW0_OPC_n(n)       ((n) << NVME_CMD_SDW0_OPC_BIT)


// Command identifier
#define NVME_CMD_SDW0_CID_GET(n) \
    (((n) >> NVME_CMD_SDW0_CID_BIT) & NVME_CMD_SDW0_CID_MASK)

// PRP or SGL data transfer
#define NVME_CMD_SDW0_PSDT_GET(n) \
    (((n) >> NVME_CMD_SDW0_PSDT_BIT) & NVME_CMD_SDW0_PSDT_MASK)

// Fused operation
#define NVME_CMD_SDW0_FUSE_GET(n) \
    (((n) >> NVME_CMD_SDW0_FUSE_BIT) & NVME_CMD_SDW0_FUSE_MASK)

// Opcode
#define NVME_CMD_SDW0_OPC_GET(n) \
    (((n) >> NVME_CMD_SDW0_OPC_BIT) & NVME_CMD_SDW0_OPC_MASK)


// Command identifier
#define NVME_CMD_SDW0_CID_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_SDW0_CID) | NVME_CMD_SDW0_CID_n((n)))

// PRP or SGL data transfer
#define NVME_CMD_SDW0_PSDT_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_SDW0_PSDT) | NVME_CMD_SDW0_PSDT_n((n)))

// Fused operation
#define NVME_CMD_SDW0_FUSE_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_SDW0_FUSE) | NVME_CMD_SDW0_FUSE_n((n)))

// Opcode
#define NVME_CMD_SDW0_OPC_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_SDW0_OPC) | NVME_CMD_SDW0_OPC_n((n)))

// NVME_CMD_CCQ_CDW10


// Queue size
#define NVME_CMD_CCQ_CDW10_QSIZE_BIT       16

// Queue identifier
#define NVME_CMD_CCQ_CDW10_QID_BIT         0


// Queue size
#define NVME_CMD_CCQ_CDW10_QSIZE_BITS      16

// Queue identifier
#define NVME_CMD_CCQ_CDW10_QID_BITS        16

// Queue size
#define NVME_CMD_CCQ_CDW10_QSIZE_MASK \
    ((1U << NVME_CMD_CCQ_CDW10_QSIZE_BITS)-1)

// Queue identifier
#define NVME_CMD_CCQ_CDW10_QID_MASK \
    ((1U << NVME_CMD_CCQ_CDW10_QID_BITS)-1)

// Queue size
#define NVME_CMD_CCQ_CDW10_QSIZE \
    (NVME_CMD_CCQ_CDW10_QSIZE_MASK << NVME_CMD_CCQ_CDW10_QSIZE_BIT)

// Queue identifier
#define NVME_CMD_CCQ_CDW10_QID \
    (NVME_CMD_CCQ_CDW10_QID_MASK << NVME_CMD_CCQ_CDW10_QID_BIT)


// Queue size
#define NVME_CMD_CCQ_CDW10_QSIZE_n(n) \
    ((n) << NVME_CMD_CCQ_CDW10_QSIZE_BIT)

// Queue identifier
#define NVME_CMD_CCQ_CDW10_QID_n(n)        ((n) << NVME_CMD_CCQ_CDW10_QID_BIT)


// Queue size
#define NVME_CMD_CCQ_CDW10_QSIZE_GET(n) \
    (((n) >> NVME_CMD_CCQ_CDW10_QSIZE_BIT) & NVME_CMD_CCQ_CDW10_QSIZE_MASK)

// Queue identifier
#define NVME_CMD_CCQ_CDW10_QID_GET(n) \
    (((n) >> NVME_CMD_CCQ_CDW10_QID_BIT) & NVME_CMD_CCQ_CDW10_QID_MASK)


// Queue size
#define NVME_CMD_CCQ_CDW10_QSIZE_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_CCQ_CDW10_QSIZE) | NVME_CMD_CCQ_CDW10_QSIZE_n((n)))

// Queue identifier
#define NVME_CMD_CCQ_CDW10_QID_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_CCQ_CDW10_QID) | NVME_CMD_CCQ_CDW10_QID_n((n)))

// NVME_CMD_CCQ_CDW11


// Interrupt vector
#define NVME_CMD_CCQ_CDW11_IV_BIT        16

// Interrupts enabled
#define NVME_CMD_CCQ_CDW11_IEN_BIT       1

// Physically contiguous
#define NVME_CMD_CCQ_CDW11_PC_BIT        0


// Interrupt vector
#define NVME_CMD_CCQ_CDW11_IV_BITS       16

// Interrupts enabled
#define NVME_CMD_CCQ_CDW11_IEN_BITS      1

// Physically contiguous
#define NVME_CMD_CCQ_CDW11_PC_BITS       1

// Interrupt vector
#define NVME_CMD_CCQ_CDW11_IV_MASK       ((1U << NVME_CMD_CCQ_CDW11_IV_BITS)-1)

// Interrupts enabled
#define NVME_CMD_CCQ_CDW11_IEN_MASK \
    ((1U << NVME_CMD_CCQ_CDW11_IEN_BITS)-1)

// Physically contiguous
#define NVME_CMD_CCQ_CDW11_PC_MASK       ((1U << NVME_CMD_CCQ_CDW11_PC_BITS)-1)

// Interrupt vector
#define NVME_CMD_CCQ_CDW11_IV \
    (NVME_CMD_CCQ_CDW11_IV_MASK << NVME_CMD_CCQ_CDW11_IV_BIT)

// Interrupts enabled
#define NVME_CMD_CCQ_CDW11_IEN \
    (NVME_CMD_CCQ_CDW11_IEN_MASK << NVME_CMD_CCQ_CDW11_IEN_BIT)

// Physically contiguous
#define NVME_CMD_CCQ_CDW11_PC \
    (NVME_CMD_CCQ_CDW11_PC_MASK << NVME_CMD_CCQ_CDW11_PC_BIT)


// Interrupt vector
#define NVME_CMD_CCQ_CDW11_IV_n(n)       ((n) << NVME_CMD_CCQ_CDW11_IV_BIT)

// Interrupts enabled
#define NVME_CMD_CCQ_CDW11_IEN_n(n)      ((n) << NVME_CMD_CCQ_CDW11_IEN_BIT)

// Physically contiguous
#define NVME_CMD_CCQ_CDW11_PC_n(n)       ((n) << NVME_CMD_CCQ_CDW11_PC_BIT)


// Interrupt vector
#define NVME_CMD_CCQ_CDW11_IV_GET(n) \
    (((n) >> NVME_CMD_CCQ_CDW11_IV_BIT) & NVME_CMD_CCQ_CDW11_IV_MASK)

// Interrupts enabled
#define NVME_CMD_CCQ_CDW11_IEN_GET(n) \
    (((n) >> NVME_CMD_CCQ_CDW11_IEN_BIT) & NVME_CMD_CCQ_CDW11_IEN_MASK)

// Physically contiguous
#define NVME_CMD_CCQ_CDW11_PC_GET(n) \
    (((n) >> NVME_CMD_CCQ_CDW11_PC_BIT) & NVME_CMD_CCQ_CDW11_PC_MASK)


// Interrupt vector
#define NVME_CMD_CCQ_CDW11_IV_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_CCQ_CDW11_IV) | NVME_CMD_CCQ_CDW11_IV_n((n)))

// Interrupts enabled
#define NVME_CMD_CCQ_CDW11_IEN_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_CCQ_CDW11_IEN) | NVME_CMD_CCQ_CDW11_IEN_n((n)))

// Physically contiguous
#define NVME_CMD_CCQ_CDW11_PC_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_CCQ_CDW11_PC) | NVME_CMD_CCQ_CDW11_PC_n((n)))

//
// NVME_CMD_CSQ_CDW10: Create I/O submission queue


// Queue size
#define NVME_CMD_CSQ_CDW10_QSIZE_BIT       16

// Queue identifier
#define NVME_CMD_CSQ_CDW10_QID_BIT         0


// Queue size
#define NVME_CMD_CSQ_CDW10_QSIZE_BITS      16

// Queue identifier
#define NVME_CMD_CSQ_CDW10_QID_BITS        16

// Queue size
#define NVME_CMD_CSQ_CDW10_QSIZE_MASK \
    ((1U << NVME_CMD_CSQ_CDW10_QSIZE_BITS)-1)

// Queue identifier
#define NVME_CMD_CSQ_CDW10_QID_MASK \
    ((1U << NVME_CMD_CSQ_CDW10_QID_BITS)-1)

// Queue size
#define NVME_CMD_CSQ_CDW10_QSIZE \
    (NVME_CMD_CSQ_CDW10_QSIZE_MASK << NVME_CMD_CSQ_CDW10_QSIZE_BIT)

// Queue identifier
#define NVME_CMD_CSQ_CDW10_QID \
    (NVME_CMD_CSQ_CDW10_QID_MASK << NVME_CMD_CSQ_CDW10_QID_BIT)


// Queue size
#define NVME_CMD_CSQ_CDW10_QSIZE_n(n) \
    ((n) << NVME_CMD_CSQ_CDW10_QSIZE_BIT)

// Queue identifier
#define NVME_CMD_CSQ_CDW10_QID_n(n)        ((n) << NVME_CMD_CSQ_CDW10_QID_BIT)


// Queue size
#define NVME_CMD_CSQ_CDW10_QSIZE_GET(n) \
    (((n) >> NVME_CMD_CSQ_CDW10_QSIZE_BIT) & NVME_CMD_CSQ_CDW10_QSIZE_MASK)

// Queue identifier
#define NVME_CMD_CSQ_CDW10_QID_GET(n) \
    (((n) >> NVME_CMD_CSQ_CDW10_QID_BIT) & NVME_CMD_CSQ_CDW10_QID_MASK)


// Queue size
#define NVME_CMD_CSQ_CDW10_QSIZE_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_CSQ_CDW10_QSIZE) | NVME_CMD_CSQ_CDW10_QSIZE_n((n)))

// Queue identifier
#define NVME_CMD_CSQ_CDW10_QID_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_CSQ_CDW10_QID) | NVME_CMD_CSQ_CDW10_QID_n((n)))

//
// NVME_CMD_CSQ_CDW11: Create I/O submission queue


// Completion queue identifier
#define NVME_CMD_CSQ_CDW11_CQID_BIT        16

// Queue priority
#define NVME_CMD_CSQ_CDW11_QPRIO_BIT       1

// Physically contiguous
#define NVME_CMD_CSQ_CDW11_PC_BIT          0


// Completion queue identifier
#define NVME_CMD_CSQ_CDW11_CQID_BITS       16

// Queue priority
#define NVME_CMD_CSQ_CDW11_QPRIO_BITS      2

// Physically contiguous
#define NVME_CMD_CSQ_CDW11_PC_BITS         1

// Completion queue identifier
#define NVME_CMD_CSQ_CDW11_CQID_MASK \
    ((1U << NVME_CMD_CSQ_CDW11_CQID_BITS)-1)

// Queue priority
#define NVME_CMD_CSQ_CDW11_QPRIO_MASK \
    ((1U << NVME_CMD_CSQ_CDW11_QPRIO_BITS)-1)

// Physically contiguous
#define NVME_CMD_CSQ_CDW11_PC_MASK \
    ((1U << NVME_CMD_CSQ_CDW11_PC_BITS)-1)

// Completion queue identifier
#define NVME_CMD_CSQ_CDW11_CQID \
    (NVME_CMD_CSQ_CDW11_CQID_MASK << NVME_CMD_CSQ_CDW11_CQID_BIT)

// Queue priority
#define NVME_CMD_CSQ_CDW11_QPRIO \
    (NVME_CMD_CSQ_CDW11_QPRIO_MASK << NVME_CMD_CSQ_CDW11_QPRIO_BIT)

// Physically contiguous
#define NVME_CMD_CSQ_CDW11_PC \
    (NVME_CMD_CSQ_CDW11_PC_MASK << NVME_CMD_CSQ_CDW11_PC_BIT)


// Completion queue identifier
#define NVME_CMD_CSQ_CDW11_CQID_n(n)       ((n) << NVME_CMD_CSQ_CDW11_CQID_BIT)

// Queue priority
#define NVME_CMD_CSQ_CDW11_QPRIO_n(n) \
    ((n) << NVME_CMD_CSQ_CDW11_QPRIO_BIT)

// Physically contiguous
#define NVME_CMD_CSQ_CDW11_PC_n(n)         ((n) << NVME_CMD_CSQ_CDW11_PC_BIT)


// Completion queue identifier
#define NVME_CMD_CSQ_CDW11_CQID_GET(n) \
    (((n) >> NVME_CMD_CSQ_CDW11_CQID_BIT) & NVME_CMD_CSQ_CDW11_CQID_MASK)

// Queue priority
#define NVME_CMD_CSQ_CDW11_QPRIO_GET(n) \
    (((n) >> NVME_CMD_CSQ_CDW11_QPRIO_BIT) & NVME_CMD_CSQ_CDW11_QPRIO_MASK)

// Physically contiguous
#define NVME_CMD_CSQ_CDW11_PC_GET(n) \
    (((n) >> NVME_CMD_CSQ_CDW11_PC_BIT) & NVME_CMD_CSQ_CDW11_PC_MASK)


// Completion queue identifier
#define NVME_CMD_CSQ_CDW11_CQID_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_CSQ_CDW11_CQID) | NVME_CMD_CSQ_CDW11_CQID_n((n)))

// Queue priority
#define NVME_CMD_CSQ_CDW11_QPRIO_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_CSQ_CDW11_QPRIO) | NVME_CMD_CSQ_CDW11_QPRIO_n((n)))

// Physically contiguous
#define NVME_CMD_CSQ_CDW11_PC_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_CSQ_CDW11_PC) | NVME_CMD_CSQ_CDW11_PC_n((n)))

// NVME_CMD_READ_CDW10


// Starting LBA low
#define NVME_CMD_READ_CDW10_SLBA_BIT       0


// Starting LBA low
#define NVME_CMD_READ_CDW10_SLBA_BITS      32

// Starting LBA low
#define NVME_CMD_READ_CDW10_SLBA_MASK \
    ((1U << NVME_CMD_READ_CDW10_SLBA_BITS)-1)

// Starting LBA low
#define NVME_CMD_READ_CDW10_SLBA \
    (NVME_CMD_READ_CDW10_SLBA_MASK << NVME_CMD_READ_CDW10_SLBA_BIT)


// Starting LBA low
#define NVME_CMD_READ_CDW10_SLBA_n(n) \
    ((n) << NVME_CMD_READ_CDW10_SLBA_BIT)


// Starting LBA low
#define NVME_CMD_READ_CDW10_SLBA_GET(n) \
    (((n) >> NVME_CMD_READ_CDW10_SLBA_BIT) & NVME_CMD_READ_CDW10_SLBA_MASK)


// Starting LBA low
#define NVME_CMD_READ_CDW10_SLBA_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_READ_CDW10_SLBA) | NVME_CMD_READ_CDW10_SLBA_n((n)))

// NVME_CMD_READ_CDW11


// Starting LBA high
#define NVME_CMD_READ_CDW11_SLBA_BIT       0


// Starting LBA high
#define NVME_CMD_READ_CDW11_SLBA_BITS      32

// Starting LBA high
#define NVME_CMD_READ_CDW11_SLBA_MASK \
    ((1U << NVME_CMD_READ_CDW11_SLBA_BITS)-1)

// Starting LBA high
#define NVME_CMD_READ_CDW11_SLBA \
    (NVME_CMD_READ_CDW11_SLBA_MASK << NVME_CMD_READ_CDW11_SLBA_BIT)


// Starting LBA high
#define NVME_CMD_READ_CDW11_SLBA_n(n) \
    ((n) << NVME_CMD_READ_CDW11_SLBA_BIT)


// Starting LBA high
#define NVME_CMD_READ_CDW11_SLBA_GET(n) \
    (((n) >> NVME_CMD_READ_CDW11_SLBA_BIT) & NVME_CMD_READ_CDW11_SLBA_MASK)


// Starting LBA high
#define NVME_CMD_READ_CDW11_SLBA_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_READ_CDW11_SLBA) | NVME_CMD_READ_CDW11_SLBA_n((n)))

// NVME_CMD_READ_CDW12


// Limited retry
#define NVME_CMD_READ_CDW12_LR_BIT           31

// Force unit access
#define NVME_CMD_READ_CDW12_FUA_BIT          30

// Protected information field
#define NVME_CMD_READ_CDW12_PRINFO_BIT       26

// Number of logical blocks
#define NVME_CMD_READ_CDW12_NLB_BIT          0


// Limited retry
#define NVME_CMD_READ_CDW12_LR_BITS          1

// Force unit access
#define NVME_CMD_READ_CDW12_FUA_BITS         1

// Protected information field
#define NVME_CMD_READ_CDW12_PRINFO_BITS      4

// Number of logical blocks
#define NVME_CMD_READ_CDW12_NLB_BITS         16

// Limited retry
#define NVME_CMD_READ_CDW12_LR_MASK \
    ((1U << NVME_CMD_READ_CDW12_LR_BITS)-1)

// Force unit access
#define NVME_CMD_READ_CDW12_FUA_MASK \
    ((1U << NVME_CMD_READ_CDW12_FUA_BITS)-1)

// Protected information field
#define NVME_CMD_READ_CDW12_PRINFO_MASK \
    ((1U << NVME_CMD_READ_CDW12_PRINFO_BITS)-1)

// Number of logical blocks
#define NVME_CMD_READ_CDW12_NLB_MASK \
    ((1U << NVME_CMD_READ_CDW12_NLB_BITS)-1)

// Limited retry
#define NVME_CMD_READ_CDW12_LR \
    (NVME_CMD_READ_CDW12_LR_MASK << NVME_CMD_READ_CDW12_LR_BIT)

// Force unit access
#define NVME_CMD_READ_CDW12_FUA \
    (NVME_CMD_READ_CDW12_FUA_MASK << NVME_CMD_READ_CDW12_FUA_BIT)

// Protected information field
#define NVME_CMD_READ_CDW12_PRINFO \
    (NVME_CMD_READ_CDW12_PRINFO_MASK << NVME_CMD_READ_CDW12_PRINFO_BIT)

// Number of logical blocks
#define NVME_CMD_READ_CDW12_NLB \
    (NVME_CMD_READ_CDW12_NLB_MASK << NVME_CMD_READ_CDW12_NLB_BIT)


// Limited retry
#define NVME_CMD_READ_CDW12_LR_n(n) \
    ((n) << NVME_CMD_READ_CDW12_LR_BIT)

// Force unit access
#define NVME_CMD_READ_CDW12_FUA_n(n) \
    ((n) << NVME_CMD_READ_CDW12_FUA_BIT)

// Protected information field
#define NVME_CMD_READ_CDW12_PRINFO_n(n) \
    ((n) << NVME_CMD_READ_CDW12_PRINFO_BIT)

// Number of logical blocks
#define NVME_CMD_READ_CDW12_NLB_n(n) \
    ((n) << NVME_CMD_READ_CDW12_NLB_BIT)


// Limited retry
#define NVME_CMD_READ_CDW12_LR_GET(n) \
    (((n) >> NVME_CMD_READ_CDW12_LR_BIT) & NVME_CMD_READ_CDW12_LR_MASK)

// Force unit access
#define NVME_CMD_READ_CDW12_FUA_GET(n) \
    (((n) >> NVME_CMD_READ_CDW12_FUA_BIT) & NVME_CMD_READ_CDW12_FUA_MASK)

// Protected information field
#define NVME_CMD_READ_CDW12_PRINFO_GET(n) \
    (((n) >> NVME_CMD_READ_CDW12_PRINFO_BIT) & NVME_CMD_READ_CDW12_PRINFO_MASK)

// Number of logical blocks
#define NVME_CMD_READ_CDW12_NLB_GET(n) \
    (((n) >> NVME_CMD_READ_CDW12_NLB_BIT) & NVME_CMD_READ_CDW12_NLB_MASK)


// Limited retry
#define NVME_CMD_READ_CDW12_LR_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_READ_CDW12_LR) | NVME_CMD_READ_CDW12_LR_n((n)))

// Force unit access
#define NVME_CMD_READ_CDW12_FUA_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_READ_CDW12_FUA) | NVME_CMD_READ_CDW12_FUA_n((n)))

// Protected information field
#define NVME_CMD_READ_CDW12_PRINFO_SET(r,n)  ((r) \
    = ((r) & ~NVME_CMD_READ_CDW12_PRINFO) | NVME_CMD_READ_CDW12_PRINFO_n((n)))

// Number of logical blocks
#define NVME_CMD_READ_CDW12_NLB_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_READ_CDW12_NLB) | NVME_CMD_READ_CDW12_NLB_n((n)))

// NVME_CMD_READ_CDW13


// Incompressible
#define NVME_CMD_READ_CDW13_INCOMP_BIT       7

// Sequential request
#define NVME_CMD_READ_CDW13_SEQ_BIT          6

// Latency
#define NVME_CMD_READ_CDW13_LAT_BIT          4

// Access frequency
#define NVME_CMD_READ_CDW13_AF_BIT           0


// Incompressible
#define NVME_CMD_READ_CDW13_INCOMP_BITS      1

// Sequential request
#define NVME_CMD_READ_CDW13_SEQ_BITS         1

// Latency
#define NVME_CMD_READ_CDW13_LAT_BITS         2

// Access frequency
#define NVME_CMD_READ_CDW13_AF_BITS          4

// Incompressible
#define NVME_CMD_READ_CDW13_INCOMP_MASK \
    ((1U << NVME_CMD_READ_CDW13_INCOMP_BITS)-1)

// Sequential request
#define NVME_CMD_READ_CDW13_SEQ_MASK \
    ((1U << NVME_CMD_READ_CDW13_SEQ_BITS)-1)

// Latency
#define NVME_CMD_READ_CDW13_LAT_MASK \
    ((1U << NVME_CMD_READ_CDW13_LAT_BITS)-1)

// Access frequency
#define NVME_CMD_READ_CDW13_AF_MASK \
    ((1U << NVME_CMD_READ_CDW13_AF_BITS)-1)

// Incompressible
#define NVME_CMD_READ_CDW13_INCOMP \
    (NVME_CMD_READ_CDW13_INCOMP_MASK << NVME_CMD_READ_CDW13_INCOMP_BIT)

// Sequential request
#define NVME_CMD_READ_CDW13_SEQ \
    (NVME_CMD_READ_CDW13_SEQ_MASK << NVME_CMD_READ_CDW13_SEQ_BIT)

// Latency
#define NVME_CMD_READ_CDW13_LAT \
    (NVME_CMD_READ_CDW13_LAT_MASK << NVME_CMD_READ_CDW13_LAT_BIT)

// Access frequency
#define NVME_CMD_READ_CDW13_AF \
    (NVME_CMD_READ_CDW13_AF_MASK << NVME_CMD_READ_CDW13_AF_BIT)


// Incompressible
#define NVME_CMD_READ_CDW13_INCOMP_n(n) \
    ((n) << NVME_CMD_READ_CDW13_INCOMP_BIT)

// Sequential request
#define NVME_CMD_READ_CDW13_SEQ_n(n) \
    ((n) << NVME_CMD_READ_CDW13_SEQ_BIT)

// Latency
#define NVME_CMD_READ_CDW13_LAT_n(n) \
    ((n) << NVME_CMD_READ_CDW13_LAT_BIT)

// Access frequency
#define NVME_CMD_READ_CDW13_AF_n(n) \
    ((n) << NVME_CMD_READ_CDW13_AF_BIT)


// Incompressible
#define NVME_CMD_READ_CDW13_INCOMP_GET(n) \
    (((n) >> NVME_CMD_READ_CDW13_INCOMP_BIT) & NVME_CMD_READ_CDW13_INCOMP_MASK)

// Sequential request
#define NVME_CMD_READ_CDW13_SEQ_GET(n) \
    (((n) >> NVME_CMD_READ_CDW13_SEQ_BIT) & NVME_CMD_READ_CDW13_SEQ_MASK)

// Latency
#define NVME_CMD_READ_CDW13_LAT_GET(n) \
    (((n) >> NVME_CMD_READ_CDW13_LAT_BIT) & NVME_CMD_READ_CDW13_LAT_MASK)

// Access frequency
#define NVME_CMD_READ_CDW13_AF_GET(n) \
    (((n) >> NVME_CMD_READ_CDW13_AF_BIT) & NVME_CMD_READ_CDW13_AF_MASK)


// Incompressible
#define NVME_CMD_READ_CDW13_INCOMP_SET(r,n)  ((r) \
    = ((r) & ~NVME_CMD_READ_CDW13_INCOMP) | NVME_CMD_READ_CDW13_INCOMP_n((n)))

// Sequential request
#define NVME_CMD_READ_CDW13_SEQ_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_READ_CDW13_SEQ) | NVME_CMD_READ_CDW13_SEQ_n((n)))

// Latency
#define NVME_CMD_READ_CDW13_LAT_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_READ_CDW13_LAT) | NVME_CMD_READ_CDW13_LAT_n((n)))

// Access frequency
#define NVME_CMD_READ_CDW13_AF_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_READ_CDW13_AF) | NVME_CMD_READ_CDW13_AF_n((n)))

//
// NVME_CMD_READ_CDW14: End-to-end protection


// Expected initial logical block reference tag
#define NVME_CMD_READ_CDW14_EILBRT_BIT       0


// Expected initial logical block reference tag
#define NVME_CMD_READ_CDW14_EILBRT_BITS      32

// Expected initial logical block reference tag
#define NVME_CMD_READ_CDW14_EILBRT_MASK \
    ((1U << NVME_CMD_READ_CDW14_EILBRT_BITS)-1)

// Expected initial logical block reference tag
#define NVME_CMD_READ_CDW14_EILBRT \
    (NVME_CMD_READ_CDW14_EILBRT_MASK << NVME_CMD_READ_CDW14_EILBRT_BIT)


// Expected initial logical block reference tag
#define NVME_CMD_READ_CDW14_EILBRT_n(n) \
    ((n) << NVME_CMD_READ_CDW14_EILBRT_BIT)


// Expected initial logical block reference tag
#define NVME_CMD_READ_CDW14_EILBRT_GET(n) \
    (((n) >> NVME_CMD_READ_CDW14_EILBRT_BIT) & NVME_CMD_READ_CDW14_EILBRT_MASK)


// Expected initial logical block reference tag
#define NVME_CMD_READ_CDW14_EILBRT_SET(r,n)  ((r) \
    = ((r) & ~NVME_CMD_READ_CDW14_EILBRT) | NVME_CMD_READ_CDW14_EILBRT_n((n)))

//
// NVME_CMD_READ_CDW15: End-to-end protection


// Expected logical block application tag mask
#define NVME_CMD_READ_CDW15_ELBATM_BIT       16

// Expected logical block application tag
#define NVME_CMD_READ_CDW15_ELBAT_BIT        0


// Expected logical block application tag mask
#define NVME_CMD_READ_CDW15_ELBATM_BITS      16

// Expected logical block application tag
#define NVME_CMD_READ_CDW15_ELBAT_BITS       16

// Expected logical block application tag mask
#define NVME_CMD_READ_CDW15_ELBATM_MASK \
    ((1U << NVME_CMD_READ_CDW15_ELBATM_BITS)-1)

// Expected logical block application tag
#define NVME_CMD_READ_CDW15_ELBAT_MASK \
    ((1U << NVME_CMD_READ_CDW15_ELBAT_BITS)-1)

// Expected logical block application tag mask
#define NVME_CMD_READ_CDW15_ELBATM \
    (NVME_CMD_READ_CDW15_ELBATM_MASK << NVME_CMD_READ_CDW15_ELBATM_BIT)

// Expected logical block application tag
#define NVME_CMD_READ_CDW15_ELBAT \
    (NVME_CMD_READ_CDW15_ELBAT_MASK << NVME_CMD_READ_CDW15_ELBAT_BIT)


// Expected logical block application tag mask
#define NVME_CMD_READ_CDW15_ELBATM_n(n) \
    ((n) << NVME_CMD_READ_CDW15_ELBATM_BIT)

// Expected logical block application tag
#define NVME_CMD_READ_CDW15_ELBAT_n(n) \
    ((n) << NVME_CMD_READ_CDW15_ELBAT_BIT)


// Expected logical block application tag mask
#define NVME_CMD_READ_CDW15_ELBATM_GET(n) \
    (((n) >> NVME_CMD_READ_CDW15_ELBATM_BIT) & NVME_CMD_READ_CDW15_ELBATM_MASK)

// Expected logical block application tag
#define NVME_CMD_READ_CDW15_ELBAT_GET(n) \
    (((n) >> NVME_CMD_READ_CDW15_ELBAT_BIT) & NVME_CMD_READ_CDW15_ELBAT_MASK)


// Expected logical block application tag mask
#define NVME_CMD_READ_CDW15_ELBATM_SET(r,n)  ((r) \
    = ((r) & ~NVME_CMD_READ_CDW15_ELBATM) | NVME_CMD_READ_CDW15_ELBATM_n((n)))

// Expected logical block application tag
#define NVME_CMD_READ_CDW15_ELBAT_SET(r,n)   ((r) \
    = ((r) & ~NVME_CMD_READ_CDW15_ELBAT) | NVME_CMD_READ_CDW15_ELBAT_n((n)))

// NVME_CMD_WRITE_CDW10


// Starting LBA low
#define NVME_CMD_WRITE_CDW10_SLBA_BIT       0


// Starting LBA low
#define NVME_CMD_WRITE_CDW10_SLBA_BITS      32

// Starting LBA low
#define NVME_CMD_WRITE_CDW10_SLBA_MASK \
    ((1U << NVME_CMD_WRITE_CDW10_SLBA_BITS)-1)

// Starting LBA low
#define NVME_CMD_WRITE_CDW10_SLBA \
    (NVME_CMD_WRITE_CDW10_SLBA_MASK << NVME_CMD_WRITE_CDW10_SLBA_BIT)


// Starting LBA low
#define NVME_CMD_WRITE_CDW10_SLBA_n(n) \
    ((n) << NVME_CMD_WRITE_CDW10_SLBA_BIT)


// Starting LBA low
#define NVME_CMD_WRITE_CDW10_SLBA_GET(n) \
    (((n) >> NVME_CMD_WRITE_CDW10_SLBA_BIT) & NVME_CMD_WRITE_CDW10_SLBA_MASK)


// Starting LBA low
#define NVME_CMD_WRITE_CDW10_SLBA_SET(r,n)  ((r) \
    = ((r) & ~NVME_CMD_WRITE_CDW10_SLBA) | NVME_CMD_WRITE_CDW10_SLBA_n((n)))

// NVME_CMD_WRITE_CDW11


// Starting LBA high
#define NVME_CMD_WRITE_CDW11_SLBA_BIT       0


// Starting LBA high
#define NVME_CMD_WRITE_CDW11_SLBA_BITS      32

// Starting LBA high
#define NVME_CMD_WRITE_CDW11_SLBA_MASK \
    ((1U << NVME_CMD_WRITE_CDW11_SLBA_BITS)-1)

// Starting LBA high
#define NVME_CMD_WRITE_CDW11_SLBA \
    (NVME_CMD_WRITE_CDW11_SLBA_MASK << NVME_CMD_WRITE_CDW11_SLBA_BIT)


// Starting LBA high
#define NVME_CMD_WRITE_CDW11_SLBA_n(n) \
    ((n) << NVME_CMD_WRITE_CDW11_SLBA_BIT)


// Starting LBA high
#define NVME_CMD_WRITE_CDW11_SLBA_GET(n) \
    (((n) >> NVME_CMD_WRITE_CDW11_SLBA_BIT) & NVME_CMD_WRITE_CDW11_SLBA_MASK)


// Starting LBA high
#define NVME_CMD_WRITE_CDW11_SLBA_SET(r,n)  ((r) \
    = ((r) & ~NVME_CMD_WRITE_CDW11_SLBA) | NVME_CMD_WRITE_CDW11_SLBA_n((n)))

// NVME_CMD_WRITE_CDW12


// Limited retry
#define NVME_CMD_WRITE_CDW12_LR_BIT           31

// Force unit access
#define NVME_CMD_WRITE_CDW12_FUA_BIT          30

// Protected information field
#define NVME_CMD_WRITE_CDW12_PRINFO_BIT       26

// Number of logical blocks
#define NVME_CMD_WRITE_CDW12_NLB_BIT          0


// Limited retry
#define NVME_CMD_WRITE_CDW12_LR_BITS          1

// Force unit access
#define NVME_CMD_WRITE_CDW12_FUA_BITS         1

// Protected information field
#define NVME_CMD_WRITE_CDW12_PRINFO_BITS      4

// Number of logical blocks
#define NVME_CMD_WRITE_CDW12_NLB_BITS         16

// Limited retry
#define NVME_CMD_WRITE_CDW12_LR_MASK \
    ((1U << NVME_CMD_WRITE_CDW12_LR_BITS)-1)

// Force unit access
#define NVME_CMD_WRITE_CDW12_FUA_MASK \
    ((1U << NVME_CMD_WRITE_CDW12_FUA_BITS)-1)

// Protected information field
#define NVME_CMD_WRITE_CDW12_PRINFO_MASK \
    ((1U << NVME_CMD_WRITE_CDW12_PRINFO_BITS)-1)

// Number of logical blocks
#define NVME_CMD_WRITE_CDW12_NLB_MASK \
    ((1U << NVME_CMD_WRITE_CDW12_NLB_BITS)-1)

// Limited retry
#define NVME_CMD_WRITE_CDW12_LR \
    (NVME_CMD_WRITE_CDW12_LR_MASK << NVME_CMD_WRITE_CDW12_LR_BIT)

// Force unit access
#define NVME_CMD_WRITE_CDW12_FUA \
    (NVME_CMD_WRITE_CDW12_FUA_MASK << NVME_CMD_WRITE_CDW12_FUA_BIT)

// Protected information field
#define NVME_CMD_WRITE_CDW12_PRINFO \
    (NVME_CMD_WRITE_CDW12_PRINFO_MASK << NVME_CMD_WRITE_CDW12_PRINFO_BIT)

// Number of logical blocks
#define NVME_CMD_WRITE_CDW12_NLB \
    (NVME_CMD_WRITE_CDW12_NLB_MASK << NVME_CMD_WRITE_CDW12_NLB_BIT)


// Limited retry
#define NVME_CMD_WRITE_CDW12_LR_n(n) \
    ((n) << NVME_CMD_WRITE_CDW12_LR_BIT)

// Force unit access
#define NVME_CMD_WRITE_CDW12_FUA_n(n) \
    ((n) << NVME_CMD_WRITE_CDW12_FUA_BIT)

// Protected information field
#define NVME_CMD_WRITE_CDW12_PRINFO_n(n) \
    ((n) << NVME_CMD_WRITE_CDW12_PRINFO_BIT)

// Number of logical blocks
#define NVME_CMD_WRITE_CDW12_NLB_n(n) \
    ((n) << NVME_CMD_WRITE_CDW12_NLB_BIT)


// Limited retry
#define NVME_CMD_WRITE_CDW12_LR_GET(n) \
    (((n) >> NVME_CMD_WRITE_CDW12_LR_BIT) & NVME_CMD_WRITE_CDW12_LR_MASK)

// Force unit access
#define NVME_CMD_WRITE_CDW12_FUA_GET(n) \
    (((n) >> NVME_CMD_WRITE_CDW12_FUA_BIT) & NVME_CMD_WRITE_CDW12_FUA_MASK)

// Protected information field
#define NVME_CMD_WRITE_CDW12_PRINFO_GET(n)    (((n) \
    >> NVME_CMD_WRITE_CDW12_PRINFO_BIT) & NVME_CMD_WRITE_CDW12_PRINFO_MASK)

// Number of logical blocks
#define NVME_CMD_WRITE_CDW12_NLB_GET(n) \
    (((n) >> NVME_CMD_WRITE_CDW12_NLB_BIT) & NVME_CMD_WRITE_CDW12_NLB_MASK)


// Limited retry
#define NVME_CMD_WRITE_CDW12_LR_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_WRITE_CDW12_LR) | NVME_CMD_WRITE_CDW12_LR_n((n)))

// Force unit access
#define NVME_CMD_WRITE_CDW12_FUA_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_WRITE_CDW12_FUA) | NVME_CMD_WRITE_CDW12_FUA_n((n)))

// Protected information field
#define NVME_CMD_WRITE_CDW12_PRINFO_SET(r,n)  ((r) = \
    ((r) & ~NVME_CMD_WRITE_CDW12_PRINFO) | NVME_CMD_WRITE_CDW12_PRINFO_n((n)))

// Number of logical blocks
#define NVME_CMD_WRITE_CDW12_NLB_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_WRITE_CDW12_NLB) | NVME_CMD_WRITE_CDW12_NLB_n((n)))

// NVME_CMD_WRITE_CDW13


// Incompressible
#define NVME_CMD_WRITE_CDW13_INCOMP_BIT       7

// Sequential request
#define NVME_CMD_WRITE_CDW13_SEQ_BIT          6

// Latency
#define NVME_CMD_WRITE_CDW13_LAT_BIT          4

// Access frequency
#define NVME_CMD_WRITE_CDW13_AF_BIT           0


// Incompressible
#define NVME_CMD_WRITE_CDW13_INCOMP_BITS      1

// Sequential request
#define NVME_CMD_WRITE_CDW13_SEQ_BITS         1

// Latency
#define NVME_CMD_WRITE_CDW13_LAT_BITS         2

// Access frequency
#define NVME_CMD_WRITE_CDW13_AF_BITS          4

// Incompressible
#define NVME_CMD_WRITE_CDW13_INCOMP_MASK \
    ((1U << NVME_CMD_WRITE_CDW13_INCOMP_BITS)-1)

// Sequential request
#define NVME_CMD_WRITE_CDW13_SEQ_MASK \
    ((1U << NVME_CMD_WRITE_CDW13_SEQ_BITS)-1)

// Latency
#define NVME_CMD_WRITE_CDW13_LAT_MASK \
    ((1U << NVME_CMD_WRITE_CDW13_LAT_BITS)-1)

// Access frequency
#define NVME_CMD_WRITE_CDW13_AF_MASK \
    ((1U << NVME_CMD_WRITE_CDW13_AF_BITS)-1)

// Incompressible
#define NVME_CMD_WRITE_CDW13_INCOMP \
    (NVME_CMD_WRITE_CDW13_INCOMP_MASK << NVME_CMD_WRITE_CDW13_INCOMP_BIT)

// Sequential request
#define NVME_CMD_WRITE_CDW13_SEQ \
    (NVME_CMD_WRITE_CDW13_SEQ_MASK << NVME_CMD_WRITE_CDW13_SEQ_BIT)

// Latency
#define NVME_CMD_WRITE_CDW13_LAT \
    (NVME_CMD_WRITE_CDW13_LAT_MASK << NVME_CMD_WRITE_CDW13_LAT_BIT)

// Access frequency
#define NVME_CMD_WRITE_CDW13_AF \
    (NVME_CMD_WRITE_CDW13_AF_MASK << NVME_CMD_WRITE_CDW13_AF_BIT)


// Incompressible
#define NVME_CMD_WRITE_CDW13_INCOMP_n(n) \
    ((n) << NVME_CMD_WRITE_CDW13_INCOMP_BIT)

// Sequential request
#define NVME_CMD_WRITE_CDW13_SEQ_n(n) \
    ((n) << NVME_CMD_WRITE_CDW13_SEQ_BIT)

// Latency
#define NVME_CMD_WRITE_CDW13_LAT_n(n) \
    ((n) << NVME_CMD_WRITE_CDW13_LAT_BIT)

// Access frequency
#define NVME_CMD_WRITE_CDW13_AF_n(n) \
    ((n) << NVME_CMD_WRITE_CDW13_AF_BIT)


// Incompressible
#define NVME_CMD_WRITE_CDW13_INCOMP_GET(n)    (((n) \
    >> NVME_CMD_WRITE_CDW13_INCOMP_BIT) & NVME_CMD_WRITE_CDW13_INCOMP_MASK)

// Sequential request
#define NVME_CMD_WRITE_CDW13_SEQ_GET(n) \
    (((n) >> NVME_CMD_WRITE_CDW13_SEQ_BIT) & NVME_CMD_WRITE_CDW13_SEQ_MASK)

// Latency
#define NVME_CMD_WRITE_CDW13_LAT_GET(n) \
    (((n) >> NVME_CMD_WRITE_CDW13_LAT_BIT) & NVME_CMD_WRITE_CDW13_LAT_MASK)

// Access frequency
#define NVME_CMD_WRITE_CDW13_AF_GET(n) \
    (((n) >> NVME_CMD_WRITE_CDW13_AF_BIT) & NVME_CMD_WRITE_CDW13_AF_MASK)


// Incompressible
#define NVME_CMD_WRITE_CDW13_INCOMP_SET(r,n)  ((r) = \
    ((r) & ~NVME_CMD_WRITE_CDW13_INCOMP) | NVME_CMD_WRITE_CDW13_INCOMP_n((n)))

// Sequential request
#define NVME_CMD_WRITE_CDW13_SEQ_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_WRITE_CDW13_SEQ) | NVME_CMD_WRITE_CDW13_SEQ_n((n)))

// Latency
#define NVME_CMD_WRITE_CDW13_LAT_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_WRITE_CDW13_LAT) | NVME_CMD_WRITE_CDW13_LAT_n((n)))

// Access frequency
#define NVME_CMD_WRITE_CDW13_AF_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_WRITE_CDW13_AF) | NVME_CMD_WRITE_CDW13_AF_n((n)))

//
// NVME_CMP_DW2: Completion queue entry dword 2


// Submission queue ID
#define NVME_CMP_DW2_SQID_BIT       16

// Submission queue head pointer
#define NVME_CMP_DW2_SQHD_BIT       0


// Submission queue ID
#define NVME_CMP_DW2_SQID_BITS      16

// Submission queue head pointer
#define NVME_CMP_DW2_SQHD_BITS      16

// Submission queue ID
#define NVME_CMP_DW2_SQID_MASK      ((1U << NVME_CMP_DW2_SQID_BITS)-1)

// Submission queue head pointer
#define NVME_CMP_DW2_SQHD_MASK      ((1U << NVME_CMP_DW2_SQHD_BITS)-1)

// Submission queue ID
#define NVME_CMP_DW2_SQID \
    (NVME_CMP_DW2_SQID_MASK << NVME_CMP_DW2_SQID_BIT)

// Submission queue head pointer
#define NVME_CMP_DW2_SQHD \
    (NVME_CMP_DW2_SQHD_MASK << NVME_CMP_DW2_SQHD_BIT)


// Submission queue ID
#define NVME_CMP_DW2_SQID_n(n)      ((n) << NVME_CMP_DW2_SQID_BIT)

// Submission queue head pointer
#define NVME_CMP_DW2_SQHD_n(n)      ((n) << NVME_CMP_DW2_SQHD_BIT)


// Submission queue ID
#define NVME_CMP_DW2_SQID_GET(n) \
    (((n) >> NVME_CMP_DW2_SQID_BIT) & NVME_CMP_DW2_SQID_MASK)

// Submission queue head pointer
#define NVME_CMP_DW2_SQHD_GET(n) \
    (((n) >> NVME_CMP_DW2_SQHD_BIT) & NVME_CMP_DW2_SQHD_MASK)


// Submission queue ID
#define NVME_CMP_DW2_SQID_SET(r,n) \
    ((r) = ((r) & ~NVME_CMP_DW2_SQID) | NVME_CMP_DW2_SQID_n((n)))

// Submission queue head pointer
#define NVME_CMP_DW2_SQHD_SET(r,n) \
    ((r) = ((r) & ~NVME_CMP_DW2_SQHD) | NVME_CMP_DW2_SQHD_n((n)))

//
// NVME_CMP_DW3: Completion queue entry dword 3


// Do not retry (0 if retry might succeed)
#define NVME_CMP_DW3_DNR_BIT       31

// More information is part of the Error Information log
#define NVME_CMP_DW3_M_BIT         30

// Status code type
#define NVME_CMP_DW3_SCT_BIT       25

// Status code
#define NVME_CMP_DW3_SC_BIT        17

// Phase tag
#define NVME_CMP_DW3_P_BIT         16

// Command ID
#define NVME_CMP_DW3_CID_BIT       0


// Do not retry (0 if retry might succeed)
#define NVME_CMP_DW3_DNR_BITS      1

// More information is part of the Error Information log
#define NVME_CMP_DW3_M_BITS        1

// Status code type
#define NVME_CMP_DW3_SCT_BITS      3

// Status code
#define NVME_CMP_DW3_SC_BITS       8

// Phase tag
#define NVME_CMP_DW3_P_BITS        1

// Command ID
#define NVME_CMP_DW3_CID_BITS      16

// Do not retry (0 if retry might succeed)
#define NVME_CMP_DW3_DNR_MASK      ((1U << NVME_CMP_DW3_DNR_BITS)-1)

// More information is part of the Error Information log
#define NVME_CMP_DW3_M_MASK        ((1U << NVME_CMP_DW3_M_BITS)-1)

// Status code type
#define NVME_CMP_DW3_SCT_MASK      ((1U << NVME_CMP_DW3_SCT_BITS)-1)

// Status code
#define NVME_CMP_DW3_SC_MASK       ((1U << NVME_CMP_DW3_SC_BITS)-1)

// Phase tag
#define NVME_CMP_DW3_P_MASK        ((1U << NVME_CMP_DW3_P_BITS)-1)

// Command ID
#define NVME_CMP_DW3_CID_MASK      ((1U << NVME_CMP_DW3_CID_BITS)-1)

// Do not retry (0 if retry might succeed)
#define NVME_CMP_DW3_DNR \
    (NVME_CMP_DW3_DNR_MASK << NVME_CMP_DW3_DNR_BIT)

// More information is part of the Error Information log
#define NVME_CMP_DW3_M             (NVME_CMP_DW3_M_MASK << NVME_CMP_DW3_M_BIT)

// Status code type
#define NVME_CMP_DW3_SCT \
    (NVME_CMP_DW3_SCT_MASK << NVME_CMP_DW3_SCT_BIT)

// Status code
#define NVME_CMP_DW3_SC \
    (NVME_CMP_DW3_SC_MASK << NVME_CMP_DW3_SC_BIT)

// Phase tag
#define NVME_CMP_DW3_P             (NVME_CMP_DW3_P_MASK << NVME_CMP_DW3_P_BIT)

// Command ID
#define NVME_CMP_DW3_CID \
    (NVME_CMP_DW3_CID_MASK << NVME_CMP_DW3_CID_BIT)


// Do not retry (0 if retry might succeed)
#define NVME_CMP_DW3_DNR_n(n)      ((n) << NVME_CMP_DW3_DNR_BIT)

// More information is part of the Error Information log
#define NVME_CMP_DW3_M_n(n)        ((n) << NVME_CMP_DW3_M_BIT)

// Status code type
#define NVME_CMP_DW3_SCT_n(n)      ((n) << NVME_CMP_DW3_SCT_BIT)

// Status code
#define NVME_CMP_DW3_SC_n(n)       ((n) << NVME_CMP_DW3_SC_BIT)

// Phase tag
#define NVME_CMP_DW3_P_n(n)        ((n) << NVME_CMP_DW3_P_BIT)

// Command ID
#define NVME_CMP_DW3_CID_n(n)      ((n) << NVME_CMP_DW3_CID_BIT)


// Do not retry (0 if retry might succeed)
#define NVME_CMP_DW3_DNR_GET(n) \
    (((n) >> NVME_CMP_DW3_DNR_BIT) & NVME_CMP_DW3_DNR_MASK)

// More information is part of the Error Information log
#define NVME_CMP_DW3_M_GET(n) \
    (((n) >> NVME_CMP_DW3_M_BIT) & NVME_CMP_DW3_M_MASK)

// Status code type
#define NVME_CMP_DW3_SCT_GET(n) \
    (((n) >> NVME_CMP_DW3_SCT_BIT) & NVME_CMP_DW3_SCT_MASK)

// Status code
#define NVME_CMP_DW3_SC_GET(n) \
    (((n) >> NVME_CMP_DW3_SC_BIT) & NVME_CMP_DW3_SC_MASK)

// Phase tag
#define NVME_CMP_DW3_P_GET(n) \
    (((n) >> NVME_CMP_DW3_P_BIT) & NVME_CMP_DW3_P_MASK)

// Command ID
#define NVME_CMP_DW3_CID_GET(n) \
    (((n) >> NVME_CMP_DW3_CID_BIT) & NVME_CMP_DW3_CID_MASK)


// Do not retry (0 if retry might succeed)
#define NVME_CMP_DW3_DNR_SET(r,n) \
    ((r) = ((r) & ~NVME_CMP_DW3_DNR) | NVME_CMP_DW3_DNR_n((n)))

// More information is part of the Error Information log
#define NVME_CMP_DW3_M_SET(r,n) \
    ((r) = ((r) & ~NVME_CMP_DW3_M) | NVME_CMP_DW3_M_n((n)))

// Status code type
#define NVME_CMP_DW3_SCT_SET(r,n) \
    ((r) = ((r) & ~NVME_CMP_DW3_SCT) | NVME_CMP_DW3_SCT_n((n)))

// Status code
#define NVME_CMP_DW3_SC_SET(r,n) \
    ((r) = ((r) & ~NVME_CMP_DW3_SC) | NVME_CMP_DW3_SC_n((n)))

// Phase tag
#define NVME_CMP_DW3_P_SET(r,n) \
    ((r) = ((r) & ~NVME_CMP_DW3_P) | NVME_CMP_DW3_P_n((n)))

// Command ID
#define NVME_CMP_DW3_CID_SET(r,n) \
    ((r) = ((r) & ~NVME_CMP_DW3_CID) | NVME_CMP_DW3_CID_n((n)))

//
// NVME_CMD_IDENT_CDW10: Identify command dword 10


// Controller identifier
#define NVME_CMD_IDENT_CDW10_CNTID_BIT       16

// Controller or namespace structure
#define NVME_CMD_IDENT_CDW10_CNS_BIT         0


// Controller identifier
#define NVME_CMD_IDENT_CDW10_CNTID_BITS      16

// Controller or namespace structure
#define NVME_CMD_IDENT_CDW10_CNS_BITS        8

// Controller identifier
#define NVME_CMD_IDENT_CDW10_CNTID_MASK \
    ((1U << NVME_CMD_IDENT_CDW10_CNTID_BITS)-1)

// Controller or namespace structure
#define NVME_CMD_IDENT_CDW10_CNS_MASK \
    ((1U << NVME_CMD_IDENT_CDW10_CNS_BITS)-1)

// Controller identifier
#define NVME_CMD_IDENT_CDW10_CNTID \
    (NVME_CMD_IDENT_CDW10_CNTID_MASK << NVME_CMD_IDENT_CDW10_CNTID_BIT)

// Controller or namespace structure
#define NVME_CMD_IDENT_CDW10_CNS \
    (NVME_CMD_IDENT_CDW10_CNS_MASK << NVME_CMD_IDENT_CDW10_CNS_BIT)


// Controller identifier
#define NVME_CMD_IDENT_CDW10_CNTID_n(n) \
    ((n) << NVME_CMD_IDENT_CDW10_CNTID_BIT)

// Controller or namespace structure
#define NVME_CMD_IDENT_CDW10_CNS_n(n) \
    ((n) << NVME_CMD_IDENT_CDW10_CNS_BIT)


// Controller identifier
#define NVME_CMD_IDENT_CDW10_CNTID_GET(n) \
    (((n) >> NVME_CMD_IDENT_CDW10_CNTID_BIT) & NVME_CMD_IDENT_CDW10_CNTID_MASK)

// Controller or namespace structure
#define NVME_CMD_IDENT_CDW10_CNS_GET(n) \
    (((n) >> NVME_CMD_IDENT_CDW10_CNS_BIT) & NVME_CMD_IDENT_CDW10_CNS_MASK)


// Controller identifier
#define NVME_CMD_IDENT_CDW10_CNTID_SET(r,n)  ((r) \
    = ((r) & ~NVME_CMD_IDENT_CDW10_CNTID) | NVME_CMD_IDENT_CDW10_CNTID_n((n)))

// Controller or namespace structure
#define NVME_CMD_IDENT_CDW10_CNS_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_IDENT_CDW10_CNS) | NVME_CMD_IDENT_CDW10_CNS_n((n)))

// NVME_NS_IDENT_FLBAS


// Metadata at end of data
#define NVME_NS_IDENT_FLBAS_EXTLBA_BIT       4

// Index of formatted LBA in lbaf
#define NVME_NS_IDENT_FLBAS_LBAIDX_BIT       0


// Metadata at end of data
#define NVME_NS_IDENT_FLBAS_EXTLBA_BITS      1

// Index of formatted LBA in lbaf
#define NVME_NS_IDENT_FLBAS_LBAIDX_BITS      4

// Metadata at end of data
#define NVME_NS_IDENT_FLBAS_EXTLBA_MASK \
    ((1U << NVME_NS_IDENT_FLBAS_EXTLBA_BITS)-1)

// Index of formatted LBA in lbaf
#define NVME_NS_IDENT_FLBAS_LBAIDX_MASK \
    ((1U << NVME_NS_IDENT_FLBAS_LBAIDX_BITS)-1)

// Metadata at end of data
#define NVME_NS_IDENT_FLBAS_EXTLBA \
    (NVME_NS_IDENT_FLBAS_EXTLBA_MASK << NVME_NS_IDENT_FLBAS_EXTLBA_BIT)

// Index of formatted LBA in lbaf
#define NVME_NS_IDENT_FLBAS_LBAIDX \
    (NVME_NS_IDENT_FLBAS_LBAIDX_MASK << NVME_NS_IDENT_FLBAS_LBAIDX_BIT)


// Metadata at end of data
#define NVME_NS_IDENT_FLBAS_EXTLBA_n(n) \
    ((n) << NVME_NS_IDENT_FLBAS_EXTLBA_BIT)

// Index of formatted LBA in lbaf
#define NVME_NS_IDENT_FLBAS_LBAIDX_n(n) \
    ((n) << NVME_NS_IDENT_FLBAS_LBAIDX_BIT)


// Metadata at end of data
#define NVME_NS_IDENT_FLBAS_EXTLBA_GET(n) \
    (((n) >> NVME_NS_IDENT_FLBAS_EXTLBA_BIT) & NVME_NS_IDENT_FLBAS_EXTLBA_MASK)

// Index of formatted LBA in lbaf
#define NVME_NS_IDENT_FLBAS_LBAIDX_GET(n) \
    (((n) >> NVME_NS_IDENT_FLBAS_LBAIDX_BIT) & NVME_NS_IDENT_FLBAS_LBAIDX_MASK)


// Metadata at end of data
#define NVME_NS_IDENT_FLBAS_EXTLBA_SET(r,n)  ((r) \
    = ((r) & ~NVME_NS_IDENT_FLBAS_EXTLBA) | NVME_NS_IDENT_FLBAS_EXTLBA_n((n)))

// Index of formatted LBA in lbaf
#define NVME_NS_IDENT_FLBAS_LBAIDX_SET(r,n)  ((r) \
    = ((r) & ~NVME_NS_IDENT_FLBAS_LBAIDX) | NVME_NS_IDENT_FLBAS_LBAIDX_n((n)))

// NVME_NS_IDENT_LBAF


// Relative performance
#define NVME_NS_IDENT_LBAF_RP_BIT          24

// LBA data size (as power of two)
#define NVME_NS_IDENT_LBAF_LBADS_BIT       16

// Metadata size
#define NVME_NS_IDENT_LBAF_MS_BIT          0


// Relative performance
#define NVME_NS_IDENT_LBAF_RP_BITS         2

// LBA data size (as power of two)
#define NVME_NS_IDENT_LBAF_LBADS_BITS      8

// Metadata size
#define NVME_NS_IDENT_LBAF_MS_BITS         16

// Relative performance
#define NVME_NS_IDENT_LBAF_RP_MASK \
    ((1U << NVME_NS_IDENT_LBAF_RP_BITS)-1)

// LBA data size (as power of two)
#define NVME_NS_IDENT_LBAF_LBADS_MASK \
    ((1U << NVME_NS_IDENT_LBAF_LBADS_BITS)-1)

// Metadata size
#define NVME_NS_IDENT_LBAF_MS_MASK \
    ((1U << NVME_NS_IDENT_LBAF_MS_BITS)-1)

// Relative performance
#define NVME_NS_IDENT_LBAF_RP \
    (NVME_NS_IDENT_LBAF_RP_MASK << NVME_NS_IDENT_LBAF_RP_BIT)

// LBA data size (as power of two)
#define NVME_NS_IDENT_LBAF_LBADS \
    (NVME_NS_IDENT_LBAF_LBADS_MASK << NVME_NS_IDENT_LBAF_LBADS_BIT)

// Metadata size
#define NVME_NS_IDENT_LBAF_MS \
    (NVME_NS_IDENT_LBAF_MS_MASK << NVME_NS_IDENT_LBAF_MS_BIT)


// Relative performance
#define NVME_NS_IDENT_LBAF_RP_n(n)         ((n) << NVME_NS_IDENT_LBAF_RP_BIT)

// LBA data size (as power of two)
#define NVME_NS_IDENT_LBAF_LBADS_n(n) \
    ((n) << NVME_NS_IDENT_LBAF_LBADS_BIT)

// Metadata size
#define NVME_NS_IDENT_LBAF_MS_n(n)         ((n) << NVME_NS_IDENT_LBAF_MS_BIT)


// Relative performance
#define NVME_NS_IDENT_LBAF_RP_GET(n) \
    (((n) >> NVME_NS_IDENT_LBAF_RP_BIT) & NVME_NS_IDENT_LBAF_RP_MASK)

// LBA data size (as power of two)
#define NVME_NS_IDENT_LBAF_LBADS_GET(n) \
    (((n) >> NVME_NS_IDENT_LBAF_LBADS_BIT) & NVME_NS_IDENT_LBAF_LBADS_MASK)

// Metadata size
#define NVME_NS_IDENT_LBAF_MS_GET(n) \
    (((n) >> NVME_NS_IDENT_LBAF_MS_BIT) & NVME_NS_IDENT_LBAF_MS_MASK)


// Relative performance
#define NVME_NS_IDENT_LBAF_RP_SET(r,n) \
    ((r) = ((r) & ~NVME_NS_IDENT_LBAF_RP) | NVME_NS_IDENT_LBAF_RP_n((n)))

// LBA data size (as power of two)
#define NVME_NS_IDENT_LBAF_LBADS_SET(r,n) \
    ((r) = ((r) & ~NVME_NS_IDENT_LBAF_LBADS) | NVME_NS_IDENT_LBAF_LBADS_n((n)))

// Metadata size
#define NVME_NS_IDENT_LBAF_MS_SET(r,n) \
    ((r) = ((r) & ~NVME_NS_IDENT_LBAF_MS) | NVME_NS_IDENT_LBAF_MS_n((n)))

//
// NVME_CMD_DSMGMT_CDW10: Dataset management command


// Number of ranges
#define NVME_CMD_DSMGMT_CDW10_NR_BIT       0


// Number of ranges
#define NVME_CMD_DSMGMT_CDW10_NR_BITS      8

// Number of ranges
#define NVME_CMD_DSMGMT_CDW10_NR_MASK \
    ((1U << NVME_CMD_DSMGMT_CDW10_NR_BITS)-1)

// Number of ranges
#define NVME_CMD_DSMGMT_CDW10_NR \
    (NVME_CMD_DSMGMT_CDW10_NR_MASK << NVME_CMD_DSMGMT_CDW10_NR_BIT)


// Number of ranges
#define NVME_CMD_DSMGMT_CDW10_NR_n(n) \
    ((n) << NVME_CMD_DSMGMT_CDW10_NR_BIT)


// Number of ranges
#define NVME_CMD_DSMGMT_CDW10_NR_GET(n) \
    (((n) >> NVME_CMD_DSMGMT_CDW10_NR_BIT) & NVME_CMD_DSMGMT_CDW10_NR_MASK)


// Number of ranges
#define NVME_CMD_DSMGMT_CDW10_NR_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_DSMGMT_CDW10_NR) | NVME_CMD_DSMGMT_CDW10_NR_n((n)))

//
// NVME_CMD_DSMGMT_CDW11: Dataset management command


// Deallocate
#define NVME_CMD_DSMGMT_CDW11_AD_BIT        2

// Integral dataset for write
#define NVME_CMD_DSMGMT_CDW11_IDW_BIT       1

// Integram dataset for read
#define NVME_CMD_DSMGMT_CDW11_IDR_BIT       0


// Deallocate
#define NVME_CMD_DSMGMT_CDW11_AD_BITS       1

// Integral dataset for write
#define NVME_CMD_DSMGMT_CDW11_IDW_BITS      1

// Integram dataset for read
#define NVME_CMD_DSMGMT_CDW11_IDR_BITS      1

// Deallocate
#define NVME_CMD_DSMGMT_CDW11_AD_MASK \
    ((1U << NVME_CMD_DSMGMT_CDW11_AD_BITS)-1)

// Integral dataset for write
#define NVME_CMD_DSMGMT_CDW11_IDW_MASK \
    ((1U << NVME_CMD_DSMGMT_CDW11_IDW_BITS)-1)

// Integram dataset for read
#define NVME_CMD_DSMGMT_CDW11_IDR_MASK \
    ((1U << NVME_CMD_DSMGMT_CDW11_IDR_BITS)-1)

// Deallocate
#define NVME_CMD_DSMGMT_CDW11_AD \
    (NVME_CMD_DSMGMT_CDW11_AD_MASK << NVME_CMD_DSMGMT_CDW11_AD_BIT)

// Integral dataset for write
#define NVME_CMD_DSMGMT_CDW11_IDW \
    (NVME_CMD_DSMGMT_CDW11_IDW_MASK << NVME_CMD_DSMGMT_CDW11_IDW_BIT)

// Integram dataset for read
#define NVME_CMD_DSMGMT_CDW11_IDR \
    (NVME_CMD_DSMGMT_CDW11_IDR_MASK << NVME_CMD_DSMGMT_CDW11_IDR_BIT)


// Deallocate
#define NVME_CMD_DSMGMT_CDW11_AD_n(n) \
    ((n) << NVME_CMD_DSMGMT_CDW11_AD_BIT)

// Integral dataset for write
#define NVME_CMD_DSMGMT_CDW11_IDW_n(n) \
    ((n) << NVME_CMD_DSMGMT_CDW11_IDW_BIT)

// Integram dataset for read
#define NVME_CMD_DSMGMT_CDW11_IDR_n(n) \
    ((n) << NVME_CMD_DSMGMT_CDW11_IDR_BIT)


// Deallocate
#define NVME_CMD_DSMGMT_CDW11_AD_GET(n) \
    (((n) >> NVME_CMD_DSMGMT_CDW11_AD_BIT) & NVME_CMD_DSMGMT_CDW11_AD_MASK)

// Integral dataset for write
#define NVME_CMD_DSMGMT_CDW11_IDW_GET(n) \
    (((n) >> NVME_CMD_DSMGMT_CDW11_IDW_BIT) & NVME_CMD_DSMGMT_CDW11_IDW_MASK)

// Integram dataset for read
#define NVME_CMD_DSMGMT_CDW11_IDR_GET(n) \
    (((n) >> NVME_CMD_DSMGMT_CDW11_IDR_BIT) & NVME_CMD_DSMGMT_CDW11_IDR_MASK)


// Deallocate
#define NVME_CMD_DSMGMT_CDW11_AD_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_DSMGMT_CDW11_AD) | NVME_CMD_DSMGMT_CDW11_AD_n((n)))

// Integral dataset for write
#define NVME_CMD_DSMGMT_CDW11_IDW_SET(r,n)  ((r) \
    = ((r) & ~NVME_CMD_DSMGMT_CDW11_IDW) | NVME_CMD_DSMGMT_CDW11_IDW_n((n)))

// Integram dataset for read
#define NVME_CMD_DSMGMT_CDW11_IDR_SET(r,n)  ((r) \
    = ((r) & ~NVME_CMD_DSMGMT_CDW11_IDR) | NVME_CMD_DSMGMT_CDW11_IDR_n((n)))

//
// NVME_CMD_DSMGMT_CA: Context attributes


// Command access size
#define NVME_CMD_DSMGMT_CA_CAS_BIT       24

// Write prepare
#define NVME_CMD_DSMGMT_CA_WP_BIT        10

// Sequential write range
#define NVME_CMD_DSMGMT_CA_SW_BIT        9

// Sequential read range
#define NVME_CMD_DSMGMT_CA_SR_BIT        8

// Access latency
#define NVME_CMD_DSMGMT_CA_AL_BIT        4

// Access frequency
#define NVME_CMD_DSMGMT_CA_AF_BIT        0


// Command access size
#define NVME_CMD_DSMGMT_CA_CAS_BITS      8

// Write prepare
#define NVME_CMD_DSMGMT_CA_WP_BITS       1

// Sequential write range
#define NVME_CMD_DSMGMT_CA_SW_BITS       1

// Sequential read range
#define NVME_CMD_DSMGMT_CA_SR_BITS       1

// Access latency
#define NVME_CMD_DSMGMT_CA_AL_BITS       2

// Access frequency
#define NVME_CMD_DSMGMT_CA_AF_BITS       4

// Command access size
#define NVME_CMD_DSMGMT_CA_CAS_MASK \
    ((1U << NVME_CMD_DSMGMT_CA_CAS_BITS)-1)

// Write prepare
#define NVME_CMD_DSMGMT_CA_WP_MASK       ((1U << NVME_CMD_DSMGMT_CA_WP_BITS)-1)

// Sequential write range
#define NVME_CMD_DSMGMT_CA_SW_MASK       ((1U << NVME_CMD_DSMGMT_CA_SW_BITS)-1)

// Sequential read range
#define NVME_CMD_DSMGMT_CA_SR_MASK       ((1U << NVME_CMD_DSMGMT_CA_SR_BITS)-1)

// Access latency
#define NVME_CMD_DSMGMT_CA_AL_MASK       ((1U << NVME_CMD_DSMGMT_CA_AL_BITS)-1)

// Access frequency
#define NVME_CMD_DSMGMT_CA_AF_MASK       ((1U << NVME_CMD_DSMGMT_CA_AF_BITS)-1)

// Command access size
#define NVME_CMD_DSMGMT_CA_CAS \
    (NVME_CMD_DSMGMT_CA_CAS_MASK << NVME_CMD_DSMGMT_CA_CAS_BIT)

// Write prepare
#define NVME_CMD_DSMGMT_CA_WP \
    (NVME_CMD_DSMGMT_CA_WP_MASK << NVME_CMD_DSMGMT_CA_WP_BIT)

// Sequential write range
#define NVME_CMD_DSMGMT_CA_SW \
    (NVME_CMD_DSMGMT_CA_SW_MASK << NVME_CMD_DSMGMT_CA_SW_BIT)

// Sequential read range
#define NVME_CMD_DSMGMT_CA_SR \
    (NVME_CMD_DSMGMT_CA_SR_MASK << NVME_CMD_DSMGMT_CA_SR_BIT)

// Access latency
#define NVME_CMD_DSMGMT_CA_AL \
    (NVME_CMD_DSMGMT_CA_AL_MASK << NVME_CMD_DSMGMT_CA_AL_BIT)

// Access frequency
#define NVME_CMD_DSMGMT_CA_AF \
    (NVME_CMD_DSMGMT_CA_AF_MASK << NVME_CMD_DSMGMT_CA_AF_BIT)


// Command access size
#define NVME_CMD_DSMGMT_CA_CAS_n(n)      ((n) << NVME_CMD_DSMGMT_CA_CAS_BIT)

// Write prepare
#define NVME_CMD_DSMGMT_CA_WP_n(n)       ((n) << NVME_CMD_DSMGMT_CA_WP_BIT)

// Sequential write range
#define NVME_CMD_DSMGMT_CA_SW_n(n)       ((n) << NVME_CMD_DSMGMT_CA_SW_BIT)

// Sequential read range
#define NVME_CMD_DSMGMT_CA_SR_n(n)       ((n) << NVME_CMD_DSMGMT_CA_SR_BIT)

// Access latency
#define NVME_CMD_DSMGMT_CA_AL_n(n)       ((n) << NVME_CMD_DSMGMT_CA_AL_BIT)

// Access frequency
#define NVME_CMD_DSMGMT_CA_AF_n(n)       ((n) << NVME_CMD_DSMGMT_CA_AF_BIT)


// Command access size
#define NVME_CMD_DSMGMT_CA_CAS_GET(n) \
    (((n) >> NVME_CMD_DSMGMT_CA_CAS_BIT) & NVME_CMD_DSMGMT_CA_CAS_MASK)

// Write prepare
#define NVME_CMD_DSMGMT_CA_WP_GET(n) \
    (((n) >> NVME_CMD_DSMGMT_CA_WP_BIT) & NVME_CMD_DSMGMT_CA_WP_MASK)

// Sequential write range
#define NVME_CMD_DSMGMT_CA_SW_GET(n) \
    (((n) >> NVME_CMD_DSMGMT_CA_SW_BIT) & NVME_CMD_DSMGMT_CA_SW_MASK)

// Sequential read range
#define NVME_CMD_DSMGMT_CA_SR_GET(n) \
    (((n) >> NVME_CMD_DSMGMT_CA_SR_BIT) & NVME_CMD_DSMGMT_CA_SR_MASK)

// Access latency
#define NVME_CMD_DSMGMT_CA_AL_GET(n) \
    (((n) >> NVME_CMD_DSMGMT_CA_AL_BIT) & NVME_CMD_DSMGMT_CA_AL_MASK)

// Access frequency
#define NVME_CMD_DSMGMT_CA_AF_GET(n) \
    (((n) >> NVME_CMD_DSMGMT_CA_AF_BIT) & NVME_CMD_DSMGMT_CA_AF_MASK)


// Command access size
#define NVME_CMD_DSMGMT_CA_CAS_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_DSMGMT_CA_CAS) | NVME_CMD_DSMGMT_CA_CAS_n((n)))

// Write prepare
#define NVME_CMD_DSMGMT_CA_WP_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_DSMGMT_CA_WP) | NVME_CMD_DSMGMT_CA_WP_n((n)))

// Sequential write range
#define NVME_CMD_DSMGMT_CA_SW_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_DSMGMT_CA_SW) | NVME_CMD_DSMGMT_CA_SW_n((n)))

// Sequential read range
#define NVME_CMD_DSMGMT_CA_SR_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_DSMGMT_CA_SR) | NVME_CMD_DSMGMT_CA_SR_n((n)))

// Access latency
#define NVME_CMD_DSMGMT_CA_AL_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_DSMGMT_CA_AL) | NVME_CMD_DSMGMT_CA_AL_n((n)))

// Access frequency
#define NVME_CMD_DSMGMT_CA_AF_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_DSMGMT_CA_AF) | NVME_CMD_DSMGMT_CA_AF_n((n)))

//
// NVME_CMD_SETFEAT_CDW10: Set features command dword 10


// Save
#define NVME_CMD_SETFEAT_CDW10_SV_BIT        31

// Feature ID
#define NVME_CMD_SETFEAT_CDW10_FID_BIT       0


// Save
#define NVME_CMD_SETFEAT_CDW10_SV_BITS       1

// Feature ID
#define NVME_CMD_SETFEAT_CDW10_FID_BITS      8

// Save
#define NVME_CMD_SETFEAT_CDW10_SV_MASK \
    ((1U << NVME_CMD_SETFEAT_CDW10_SV_BITS)-1)

// Feature ID
#define NVME_CMD_SETFEAT_CDW10_FID_MASK \
    ((1U << NVME_CMD_SETFEAT_CDW10_FID_BITS)-1)

// Save
#define NVME_CMD_SETFEAT_CDW10_SV \
    (NVME_CMD_SETFEAT_CDW10_SV_MASK << NVME_CMD_SETFEAT_CDW10_SV_BIT)

// Feature ID
#define NVME_CMD_SETFEAT_CDW10_FID \
    (NVME_CMD_SETFEAT_CDW10_FID_MASK << NVME_CMD_SETFEAT_CDW10_FID_BIT)


// Save
#define NVME_CMD_SETFEAT_CDW10_SV_n(n) \
    ((n) << NVME_CMD_SETFEAT_CDW10_SV_BIT)

// Feature ID
#define NVME_CMD_SETFEAT_CDW10_FID_n(n) \
    ((n) << NVME_CMD_SETFEAT_CDW10_FID_BIT)


// Save
#define NVME_CMD_SETFEAT_CDW10_SV_GET(n) \
    (((n) >> NVME_CMD_SETFEAT_CDW10_SV_BIT) & NVME_CMD_SETFEAT_CDW10_SV_MASK)

// Feature ID
#define NVME_CMD_SETFEAT_CDW10_FID_GET(n) \
    (((n) >> NVME_CMD_SETFEAT_CDW10_FID_BIT) & NVME_CMD_SETFEAT_CDW10_FID_MASK)


// Save
#define NVME_CMD_SETFEAT_CDW10_SV_SET(r,n)   ((r) \
    = ((r) & ~NVME_CMD_SETFEAT_CDW10_SV) | NVME_CMD_SETFEAT_CDW10_SV_n((n)))

// Feature ID
#define NVME_CMD_SETFEAT_CDW10_FID_SET(r,n)  ((r) \
    = ((r) & ~NVME_CMD_SETFEAT_CDW10_FID) | NVME_CMD_SETFEAT_CDW10_FID_n((n)))

//
// NVME_CMD_SETFEAT_NQ_CDW11: Set features number of queues command dword 11


// Number of completion queues requested
#define NVME_CMD_SETFEAT_NQ_CDW11_NCQR_BIT       16

// Number of submission queues requested
#define NVME_CMD_SETFEAT_NQ_CDW11_NSQR_BIT       0


// Number of completion queues requested
#define NVME_CMD_SETFEAT_NQ_CDW11_NCQR_BITS      16

// Number of submission queues requested
#define NVME_CMD_SETFEAT_NQ_CDW11_NSQR_BITS      16

// Number of completion queues requested
#define NVME_CMD_SETFEAT_NQ_CDW11_NCQR_MASK \
    ((1U << NVME_CMD_SETFEAT_NQ_CDW11_NCQR_BITS)-1)

// Number of submission queues requested
#define NVME_CMD_SETFEAT_NQ_CDW11_NSQR_MASK \
    ((1U << NVME_CMD_SETFEAT_NQ_CDW11_NSQR_BITS)-1)

// Number of completion queues requested
#define NVME_CMD_SETFEAT_NQ_CDW11_NCQR \
    (NVME_CMD_SETFEAT_NQ_CDW11_NCQR_MASK << NVME_CMD_SETFEAT_NQ_CDW11_NCQR_BIT)

// Number of submission queues requested
#define NVME_CMD_SETFEAT_NQ_CDW11_NSQR \
    (NVME_CMD_SETFEAT_NQ_CDW11_NSQR_MASK << NVME_CMD_SETFEAT_NQ_CDW11_NSQR_BIT)


// Number of completion queues requested
#define NVME_CMD_SETFEAT_NQ_CDW11_NCQR_n(n) \
    ((n) << NVME_CMD_SETFEAT_NQ_CDW11_NCQR_BIT)

// Number of submission queues requested
#define NVME_CMD_SETFEAT_NQ_CDW11_NSQR_n(n) \
    ((n) << NVME_CMD_SETFEAT_NQ_CDW11_NSQR_BIT)


// Number of completion queues requested
#define NVME_CMD_SETFEAT_NQ_CDW11_NCQR_GET(n)    (((n) >> \
    NVME_CMD_SETFEAT_NQ_CDW11_NCQR_BIT) & NVME_CMD_SETFEAT_NQ_CDW11_NCQR_MASK)

// Number of submission queues requested
#define NVME_CMD_SETFEAT_NQ_CDW11_NSQR_GET(n)    (((n) >> \
    NVME_CMD_SETFEAT_NQ_CDW11_NSQR_BIT) & NVME_CMD_SETFEAT_NQ_CDW11_NSQR_MASK)


// Number of completion queues requested
#define NVME_CMD_SETFEAT_NQ_CDW11_NCQR_SET(r,n)  ((r) = ((r) \
    & ~NVME_CMD_SETFEAT_NQ_CDW11_NCQR) | NVME_CMD_SETFEAT_NQ_CDW11_NCQR_n((n)))

// Number of submission queues requested
#define NVME_CMD_SETFEAT_NQ_CDW11_NSQR_SET(r,n)  ((r) = ((r) \
    & ~NVME_CMD_SETFEAT_NQ_CDW11_NSQR) | NVME_CMD_SETFEAT_NQ_CDW11_NSQR_n((n)))

// NVME_CMD_SETFEAT_HMB_CDW11


// Memory return  1=returning previous HMB from before reset/sleep
#define NVME_CMD_SETFEAT_HMB_CDW11_MR_BIT        1

// Enable host memory
#define NVME_CMD_SETFEAT_HMB_CDW11_EHM_BIT       2


// Memory return  1=returning previous HMB from before reset/sleep
#define NVME_CMD_SETFEAT_HMB_CDW11_MR_BITS       1

// Enable host memory
#define NVME_CMD_SETFEAT_HMB_CDW11_EHM_BITS      1

// Memory return  1=returning previous HMB from before reset/sleep
#define NVME_CMD_SETFEAT_HMB_CDW11_MR_MASK \
    ((1U << NVME_CMD_SETFEAT_HMB_CDW11_MR_BITS)-1)

// Enable host memory
#define NVME_CMD_SETFEAT_HMB_CDW11_EHM_MASK \
    ((1U << NVME_CMD_SETFEAT_HMB_CDW11_EHM_BITS)-1)

// Memory return  1=returning previous HMB from before reset/sleep
#define NVME_CMD_SETFEAT_HMB_CDW11_MR \
    (NVME_CMD_SETFEAT_HMB_CDW11_MR_MASK << NVME_CMD_SETFEAT_HMB_CDW11_MR_BIT)

// Enable host memory
#define NVME_CMD_SETFEAT_HMB_CDW11_EHM \
    (NVME_CMD_SETFEAT_HMB_CDW11_EHM_MASK << NVME_CMD_SETFEAT_HMB_CDW11_EHM_BIT)


// Memory return  1=returning previous HMB from before reset/sleep
#define NVME_CMD_SETFEAT_HMB_CDW11_MR_n(n) \
    ((n) << NVME_CMD_SETFEAT_HMB_CDW11_MR_BIT)

// Enable host memory
#define NVME_CMD_SETFEAT_HMB_CDW11_EHM_n(n) \
    ((n) << NVME_CMD_SETFEAT_HMB_CDW11_EHM_BIT)


// Memory return  1=returning previous HMB from before reset/sleep
#define NVME_CMD_SETFEAT_HMB_CDW11_MR_GET(n)     (((n) \
    >> NVME_CMD_SETFEAT_HMB_CDW11_MR_BIT) & NVME_CMD_SETFEAT_HMB_CDW11_MR_MASK)

// Enable host memory
#define NVME_CMD_SETFEAT_HMB_CDW11_EHM_GET(n)    (((n) >> \
    NVME_CMD_SETFEAT_HMB_CDW11_EHM_BIT) & NVME_CMD_SETFEAT_HMB_CDW11_EHM_MASK)


// Memory return  1=returning previous HMB from before reset/sleep
#define NVME_CMD_SETFEAT_HMB_CDW11_MR_SET(r,n)   ((r) = ((r) \
    & ~NVME_CMD_SETFEAT_HMB_CDW11_MR) | NVME_CMD_SETFEAT_HMB_CDW11_MR_n((n)))

// Enable host memory
#define NVME_CMD_SETFEAT_HMB_CDW11_EHM_SET(r,n)  ((r) = ((r) \
    & ~NVME_CMD_SETFEAT_HMB_CDW11_EHM) | NVME_CMD_SETFEAT_HMB_CDW11_EHM_n((n)))

// NVME_CMD_SETFEAT_HMB_CDW12


// Size of host memory buffer, in pages
#define NVME_CMD_SETFEAT_HMB_CDW12_HSIZE_BIT       0


// Size of host memory buffer, in pages
#define NVME_CMD_SETFEAT_HMB_CDW12_HSIZE_BITS      32

// Size of host memory buffer, in pages
#define NVME_CMD_SETFEAT_HMB_CDW12_HSIZE_MASK \
    ((1U << NVME_CMD_SETFEAT_HMB_CDW12_HSIZE_BITS)-1)

// Size of host memory buffer, in pages
#define NVME_CMD_SETFEAT_HMB_CDW12_HSIZE \
    (NVME_CMD_SETFEAT_HMB_CDW12_HSIZE_MASK \
    << NVME_CMD_SETFEAT_HMB_CDW12_HSIZE_BIT)


// Size of host memory buffer, in pages
#define NVME_CMD_SETFEAT_HMB_CDW12_HSIZE_n(n) \
    ((n) << NVME_CMD_SETFEAT_HMB_CDW12_HSIZE_BIT)


// Size of host memory buffer, in pages
#define NVME_CMD_SETFEAT_HMB_CDW12_HSIZE_GET(n) \
    (((n) >> NVME_CMD_SETFEAT_HMB_CDW12_HSIZE_BIT) \
    & NVME_CMD_SETFEAT_HMB_CDW12_HSIZE_MASK)


// Size of host memory buffer, in pages
#define NVME_CMD_SETFEAT_HMB_CDW12_HSIZE_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_SETFEAT_HMB_CDW12_HSIZE) \
    | NVME_CMD_SETFEAT_HMB_CDW12_HSIZE_n((n)))

// NVME_CMD_SETFEAT_HMB_CDW13


// Host memory descriptor list lower address
#define NVME_CMD_SETFEAT_HMB_CDW13_HMDLLA_BIT       0


// Host memory descriptor list lower address
#define NVME_CMD_SETFEAT_HMB_CDW13_HMDLLA_BITS      32

// Host memory descriptor list lower address
#define NVME_CMD_SETFEAT_HMB_CDW13_HMDLLA_MASK \
    ((1U << NVME_CMD_SETFEAT_HMB_CDW13_HMDLLA_BITS)-1)

// Host memory descriptor list lower address
#define NVME_CMD_SETFEAT_HMB_CDW13_HMDLLA \
    (NVME_CMD_SETFEAT_HMB_CDW13_HMDLLA_MASK \
    << NVME_CMD_SETFEAT_HMB_CDW13_HMDLLA_BIT)


// Host memory descriptor list lower address
#define NVME_CMD_SETFEAT_HMB_CDW13_HMDLLA_n(n) \
    ((n) << NVME_CMD_SETFEAT_HMB_CDW13_HMDLLA_BIT)


// Host memory descriptor list lower address
#define NVME_CMD_SETFEAT_HMB_CDW13_HMDLLA_GET(n) \
    (((n) >> NVME_CMD_SETFEAT_HMB_CDW13_HMDLLA_BIT) \
    & NVME_CMD_SETFEAT_HMB_CDW13_HMDLLA_MASK)


// Host memory descriptor list lower address
#define NVME_CMD_SETFEAT_HMB_CDW13_HMDLLA_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_SETFEAT_HMB_CDW13_HMDLLA) \
    | NVME_CMD_SETFEAT_HMB_CDW13_HMDLLA_n((n)))

// NVME_CMD_SETFEAT_HMB_CDW14


// Host memory descriptor list upper address
#define NVME_CMD_SETFEAT_HMB_CDW14_HMDLUA_BIT       0


// Host memory descriptor list upper address
#define NVME_CMD_SETFEAT_HMB_CDW14_HMDLUA_BITS      32

// Host memory descriptor list upper address
#define NVME_CMD_SETFEAT_HMB_CDW14_HMDLUA_MASK \
    ((1U << NVME_CMD_SETFEAT_HMB_CDW14_HMDLUA_BITS)-1)

// Host memory descriptor list upper address
#define NVME_CMD_SETFEAT_HMB_CDW14_HMDLUA \
    (NVME_CMD_SETFEAT_HMB_CDW14_HMDLUA_MASK \
    << NVME_CMD_SETFEAT_HMB_CDW14_HMDLUA_BIT)


// Host memory descriptor list upper address
#define NVME_CMD_SETFEAT_HMB_CDW14_HMDLUA_n(n) \
    ((n) << NVME_CMD_SETFEAT_HMB_CDW14_HMDLUA_BIT)


// Host memory descriptor list upper address
#define NVME_CMD_SETFEAT_HMB_CDW14_HMDLUA_GET(n) \
    (((n) >> NVME_CMD_SETFEAT_HMB_CDW14_HMDLUA_BIT) \
    & NVME_CMD_SETFEAT_HMB_CDW14_HMDLUA_MASK)


// Host memory descriptor list upper address
#define NVME_CMD_SETFEAT_HMB_CDW14_HMDLUA_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_SETFEAT_HMB_CDW14_HMDLUA) \
    | NVME_CMD_SETFEAT_HMB_CDW14_HMDLUA_n((n)))

// NVME_CMD_SETFEAT_HMB_CDW15


// Host memory descriptor list entry count
#define NVME_CMD_SETFEAT_HMB_CDW15_HMDLEC_BIT       0


// Host memory descriptor list entry count
#define NVME_CMD_SETFEAT_HMB_CDW15_HMDLEC_BITS      32

// Host memory descriptor list entry count
#define NVME_CMD_SETFEAT_HMB_CDW15_HMDLEC_MASK \
    ((1U << NVME_CMD_SETFEAT_HMB_CDW15_HMDLEC_BITS)-1)

// Host memory descriptor list entry count
#define NVME_CMD_SETFEAT_HMB_CDW15_HMDLEC \
    (NVME_CMD_SETFEAT_HMB_CDW15_HMDLEC_MASK \
    << NVME_CMD_SETFEAT_HMB_CDW15_HMDLEC_BIT)


// Host memory descriptor list entry count
#define NVME_CMD_SETFEAT_HMB_CDW15_HMDLEC_n(n) \
    ((n) << NVME_CMD_SETFEAT_HMB_CDW15_HMDLEC_BIT)


// Host memory descriptor list entry count
#define NVME_CMD_SETFEAT_HMB_CDW15_HMDLEC_GET(n) \
    (((n) >> NVME_CMD_SETFEAT_HMB_CDW15_HMDLEC_BIT) \
    & NVME_CMD_SETFEAT_HMB_CDW15_HMDLEC_MASK)


// Host memory descriptor list entry count
#define NVME_CMD_SETFEAT_HMB_CDW15_HMDLEC_SET(r,n) \
    ((r) = ((r) & ~NVME_CMD_SETFEAT_HMB_CDW15_HMDLEC) \
    | NVME_CMD_SETFEAT_HMB_CDW15_HMDLEC_n((n)))

//
// NVME_CMP_SETFEAT_NQ_DW0: Set features number of queues completion dword 0


// Number of completion queues allocated
#define NVME_CMP_SETFEAT_NQ_DW0_NCQA_BIT       16

// Number of submission queues allocated
#define NVME_CMP_SETFEAT_NQ_DW0_NSQA_BIT       0


// Number of completion queues allocated
#define NVME_CMP_SETFEAT_NQ_DW0_NCQA_BITS      16

// Number of submission queues allocated
#define NVME_CMP_SETFEAT_NQ_DW0_NSQA_BITS      16

// Number of completion queues allocated
#define NVME_CMP_SETFEAT_NQ_DW0_NCQA_MASK \
    ((1U << NVME_CMP_SETFEAT_NQ_DW0_NCQA_BITS)-1)

// Number of submission queues allocated
#define NVME_CMP_SETFEAT_NQ_DW0_NSQA_MASK \
    ((1U << NVME_CMP_SETFEAT_NQ_DW0_NSQA_BITS)-1)

// Number of completion queues allocated
#define NVME_CMP_SETFEAT_NQ_DW0_NCQA \
    (NVME_CMP_SETFEAT_NQ_DW0_NCQA_MASK << NVME_CMP_SETFEAT_NQ_DW0_NCQA_BIT)

// Number of submission queues allocated
#define NVME_CMP_SETFEAT_NQ_DW0_NSQA \
    (NVME_CMP_SETFEAT_NQ_DW0_NSQA_MASK << NVME_CMP_SETFEAT_NQ_DW0_NSQA_BIT)


// Number of completion queues allocated
#define NVME_CMP_SETFEAT_NQ_DW0_NCQA_n(n) \
    ((n) << NVME_CMP_SETFEAT_NQ_DW0_NCQA_BIT)

// Number of submission queues allocated
#define NVME_CMP_SETFEAT_NQ_DW0_NSQA_n(n) \
    ((n) << NVME_CMP_SETFEAT_NQ_DW0_NSQA_BIT)


// Number of completion queues allocated
#define NVME_CMP_SETFEAT_NQ_DW0_NCQA_GET(n)    (((n) \
    >> NVME_CMP_SETFEAT_NQ_DW0_NCQA_BIT) & NVME_CMP_SETFEAT_NQ_DW0_NCQA_MASK)

// Number of submission queues allocated
#define NVME_CMP_SETFEAT_NQ_DW0_NSQA_GET(n)    (((n) \
    >> NVME_CMP_SETFEAT_NQ_DW0_NSQA_BIT) & NVME_CMP_SETFEAT_NQ_DW0_NSQA_MASK)


// Number of completion queues allocated
#define NVME_CMP_SETFEAT_NQ_DW0_NCQA_SET(r,n)  ((r) = ((r) \
    & ~NVME_CMP_SETFEAT_NQ_DW0_NCQA) | NVME_CMP_SETFEAT_NQ_DW0_NCQA_n((n)))

// Number of submission queues allocated
#define NVME_CMP_SETFEAT_NQ_DW0_NSQA_SET(r,n)  ((r) = ((r) \
    & ~NVME_CMP_SETFEAT_NQ_DW0_NSQA) | NVME_CMP_SETFEAT_NQ_DW0_NSQA_n((n)))

